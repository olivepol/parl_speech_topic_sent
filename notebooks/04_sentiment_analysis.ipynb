{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sample_split loaded!\n",
      "Shape: (3142, 15)\n",
      "\n",
      "Column names: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length']\n",
      "\n",
      "Data types:\n",
      "Schema([('id', Int64), ('session', Int64), ('electoralTerm', Int64), ('firstName', String), ('lastName', String), ('politicianId', Int64), ('speechContent', String), ('factionId', Int64), ('documentUrl', String), ('positionShort', String), ('positionLong', String), ('date', String), ('speech_length', Int64), ('paragraph_number', Int64), ('paragraph_length', Int64)])\n",
      "\n",
      "First few rows:\n",
      "shape: (5, 15)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id     â”† session â”† electoralT â”† firstName â”† â€¦ â”† date       â”† speech_len â”† paragraph_ â”† paragraph â”‚\n",
      "â”‚ ---    â”† ---     â”† erm        â”† ---       â”†   â”† ---        â”† gth        â”† number     â”† _length   â”‚\n",
      "â”‚ i64    â”† i64     â”† ---        â”† str       â”†   â”† str        â”† ---        â”† ---        â”† ---       â”‚\n",
      "â”‚        â”†         â”† i64        â”†           â”†   â”†            â”† i64        â”† i64        â”† i64       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 739083 â”† 43      â”† 17         â”† lukrezia  â”† â€¦ â”† 2010-05-20 â”† 3564       â”† 1          â”† 51        â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† T00:00:00. â”†            â”†            â”†           â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† 000000     â”†            â”†            â”†           â”‚\n",
      "â”‚ 739083 â”† 43      â”† 17         â”† lukrezia  â”† â€¦ â”† 2010-05-20 â”† 3564       â”† 2          â”† 520       â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† T00:00:00. â”†            â”†            â”†           â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† 000000     â”†            â”†            â”†           â”‚\n",
      "â”‚ 739083 â”† 43      â”† 17         â”† lukrezia  â”† â€¦ â”† 2010-05-20 â”† 3564       â”† 3          â”† 5         â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† T00:00:00. â”†            â”†            â”†           â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† 000000     â”†            â”†            â”†           â”‚\n",
      "â”‚ 739083 â”† 43      â”† 17         â”† lukrezia  â”† â€¦ â”† 2010-05-20 â”† 3564       â”† 4          â”† 48        â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† T00:00:00. â”†            â”†            â”†           â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† 000000     â”†            â”†            â”†           â”‚\n",
      "â”‚ 739083 â”† 43      â”† 17         â”† lukrezia  â”† â€¦ â”† 2010-05-20 â”† 3564       â”† 5          â”† 5         â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† T00:00:00. â”†            â”†            â”†           â”‚\n",
      "â”‚        â”†         â”†            â”†           â”†   â”† 000000     â”†            â”†            â”†           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the same preprocessed data as topic modeling to ensure matching IDs\n",
    "# This ensures sentiment analysis runs on the same speeches as topic modeling\n",
    "processed_dir = Path('../data/processed')\n",
    "df = pl.read_parquet(processed_dir / 'df_sample_split_preprocessed_topic.parquet')\n",
    "\n",
    "print(f\"df_sample_split_preprocessed_topic loaded!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.schema)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'negative', 'positive', 'positive', 'neutral', 'neutral']\n",
      "['positive'] [[['positive', 0.9761366844177246], ['negative', 0.02354043908417225], ['neutral', 0.0003229434078093618]]]\n"
     ]
    }
   ],
   "source": [
    "# trying the sentiment API\n",
    "\n",
    "from germansentiment import SentimentModel\n",
    "\n",
    "model = SentimentModel()\n",
    "\n",
    "texts = [\n",
    "    \"Mit keinem guten Ergebniss\",\"Das ist gar nicht mal so gut\",\n",
    "    \"Total awesome!\",\"nicht so schlecht wie erwartet\",\n",
    "    \"Der Test verlief positiv.\",\"Sie fÃ¤hrt ein grÃ¼nes Auto.\"]\n",
    "       \n",
    "result = model.predict_sentiment(texts)\n",
    "print(result)\n",
    "\n",
    "classes, probabilities = model.predict_sentiment([\"das ist super\"], output_probabilities = True) \n",
    "print(classes, probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430128a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming paragraphs longer than 300 words...\n",
      "\n",
      "Trimming complete!\n",
      "Total rows: 3142\n",
      "\n",
      "Word count statistics after trimming:\n",
      "  Min words: 1\n",
      "  Max words: 300\n",
      "  Mean words: 48.8\n",
      "  Median words: 27.0\n",
      "\n",
      "First few rows after trimming:\n",
      "shape: (5, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id     â”† word_count â”† speechContent                   â”‚\n",
      "â”‚ ---    â”† ---        â”† ---                             â”‚\n",
      "â”‚ i64    â”† u32        â”† str                             â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 739083 â”† 7          â”† Herr PrÃ¤sident! Liebe Kolleginâ€¦ â”‚\n",
      "â”‚ 739083 â”† 63         â”† total leeren TribÃ¼nen - mit Auâ€¦ â”‚\n",
      "â”‚ 739083 â”† 1          â”† ({0})                           â”‚\n",
      "â”‚ 739083 â”† 8          â”† Der Grund: So soll ein Skandalâ€¦ â”‚\n",
      "â”‚ 739083 â”† 1          â”† ({1})                           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Cut paragraphs longer than 300 words using native Polars (10-100x faster than map_elements)\n",
    "import polars as pl\n",
    "from src.utils.text_processing import trim_to_max_words_native, add_word_count\n",
    "\n",
    "print(\"Trimming paragraphs longer than 300 words...\")\n",
    "\n",
    "# Apply trimming using native Polars operations (much faster than map_elements)\n",
    "df_trimmed = trim_to_max_words_native(df, 'speechContent', max_words=300)\n",
    "\n",
    "# Calculate word counts for statistics\n",
    "df_trimmed = add_word_count(df_trimmed, 'speechContent', 'word_count')\n",
    "\n",
    "print(f\"\\nTrimming complete!\")\n",
    "print(f\"Total rows: {df_trimmed.shape[0]}\")\n",
    "print(f\"\\nWord count statistics after trimming:\")\n",
    "print(f\"  Min words: {df_trimmed['word_count'].min()}\")\n",
    "print(f\"  Max words: {df_trimmed['word_count'].max()}\")\n",
    "print(f\"  Mean words: {df_trimmed['word_count'].mean():.1f}\")\n",
    "print(f\"  Median words: {df_trimmed['word_count'].median():.1f}\")\n",
    "\n",
    "print(f\"\\nFirst few rows after trimming:\")\n",
    "print(df_trimmed.select(['id', 'word_count', 'speechContent']).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df15434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment model...\n",
      "Processing 3142 paragraphs for sentiment analysis...\n",
      "  Processed 3142 texts in 99 batches\n",
      "\n",
      "Sentiment analysis complete!\n",
      "Total paragraphs: 3142\n",
      "\n",
      "Sentiment class distribution:\n",
      "shape: (3, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ sentiment_class â”† count â”‚\n",
      "â”‚ ---             â”† ---   â”‚\n",
      "â”‚ str             â”† u32   â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ neutral         â”† 2125  â”‚\n",
      "â”‚ positive        â”† 705   â”‚\n",
      "â”‚ negative        â”† 312   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "First few results:\n",
      "shape: (5, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id     â”† word_count â”† sentiment_class â”† sentiment_probabilities         â”‚\n",
      "â”‚ ---    â”† ---        â”† ---             â”† ---                             â”‚\n",
      "â”‚ i64    â”† u32        â”† str             â”† object                          â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 739083 â”† 7          â”† neutral         â”† [['positive', 0.00488126790151â€¦ â”‚\n",
      "â”‚ 739083 â”† 63         â”† neutral         â”† [['positive', 0.00339804240502â€¦ â”‚\n",
      "â”‚ 739083 â”† 1          â”† neutral         â”† [['positive', 0.00557720288634â€¦ â”‚\n",
      "â”‚ 739083 â”† 8          â”† neutral         â”† [['positive', 0.00062033120775â€¦ â”‚\n",
      "â”‚ 739083 â”† 1          â”† positive        â”† [['positive', 0.89242458343505â€¦ â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Calculate sentiment for each paragraph using batch processing (faster)\n",
    "from germansentiment import SentimentModel\n",
    "from src.utils.text_processing import batch_process_sentiment\n",
    "import polars as pl\n",
    "\n",
    "print(\"Loading sentiment model...\")\n",
    "model = SentimentModel()\n",
    "\n",
    "print(f\"Processing {len(df_trimmed)} paragraphs for sentiment analysis...\")\n",
    "\n",
    "# Extract texts\n",
    "texts = df_trimmed['speechContent'].to_list()\n",
    "\n",
    "# Use batch processing for better performance\n",
    "sentiments, probabilities_list = batch_process_sentiment(texts, model, batch_size=32)\n",
    "\n",
    "# Add sentiment columns to dataframe\n",
    "df_sentiment = df_trimmed.with_columns([\n",
    "    pl.Series('sentiment_class', sentiments),\n",
    "    pl.Series('sentiment_probabilities', probabilities_list, dtype=pl.Object)\n",
    "])\n",
    "\n",
    "print(f\"\\nSentiment analysis complete!\")\n",
    "print(f\"Total paragraphs: {len(df_sentiment)}\")\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(f\"\\nSentiment class distribution:\")\n",
    "print(df_sentiment['sentiment_class'].value_counts().sort('count', descending=True))\n",
    "\n",
    "# Extract individual probabilities for better visualization\n",
    "print(f\"\\nFirst few results:\")\n",
    "print(df_sentiment.select(['id', 'word_count', 'sentiment_class', 'sentiment_probabilities']).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Sentiment analysis results saved!\n",
      "  File: ..\\data\\processed\\df_sample_sentiment.parquet\n",
      "  Rows: 3142\n",
      "  Columns: 18\n",
      "\n",
      "ğŸ“Š Sentiment Analysis Summary:\n",
      "  Total paragraphs analyzed: 3142\n",
      "\n",
      "  Sentiment Distribution:\n",
      "    neutral   : 2125 ( 67.6%)\n",
      "    positive  : 705 ( 22.4%)\n",
      "    negative  : 312 (  9.9%)\n",
      "\n",
      "âœ“ Data ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save sentiment analysis results (parquet only - more efficient)\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Define output path\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convert probabilities to JSON strings using map_elements\n",
    "df_to_save = df_sentiment.with_columns(\n",
    "    pl.col('sentiment_probabilities').map_elements(\n",
    "        lambda x: json.dumps(x) if x is not None else None,\n",
    "        return_dtype=pl.Utf8\n",
    "    ).alias('sentiment_probabilities')\n",
    ")\n",
    "\n",
    "# Save as Parquet only (more efficient than CSV)\n",
    "output_file = output_dir / 'df_sample_sentiment.parquet'\n",
    "df_to_save.write_parquet(output_file)\n",
    "\n",
    "print(f\"âœ“ Sentiment analysis results saved!\")\n",
    "print(f\"  File: {output_file}\")\n",
    "print(f\"  Rows: {len(df_to_save)}\")\n",
    "print(f\"  Columns: {len(df_to_save.columns)}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\nğŸ“Š Sentiment Analysis Summary:\")\n",
    "print(f\"  Total paragraphs analyzed: {len(df_sentiment)}\")\n",
    "print(f\"\\n  Sentiment Distribution:\")\n",
    "sentiment_counts = df_sentiment['sentiment_class'].value_counts().sort('count', descending=True)\n",
    "for row in sentiment_counts.iter_rows(named=True):\n",
    "    percentage = (row['count'] / len(df_sentiment)) * 100\n",
    "    print(f\"    {row['sentiment_class']:10s}: {row['count']:3d} ({percentage:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ“ Data ready for further analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parl_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
