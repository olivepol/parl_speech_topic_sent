{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6035ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data loaded!\n",
      "Shape: (588776, 23)\n",
      "\n",
      "Column names: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'tokens', 'token_count', 'tokens_no_stopwords', 'token_count_no_stopwords', 'tokens_clean', 'token_count_clean', 'tokens_lemma', 'token_count_lemma']\n",
      "\n",
      "Data types:\n",
      "Schema([('id', Int64), ('session', Int64), ('electoralTerm', Int64), ('firstName', String), ('lastName', String), ('politicianId', Int64), ('speechContent', String), ('factionId', Int64), ('documentUrl', String), ('positionShort', String), ('positionLong', String), ('date', String), ('speech_length', Int64), ('paragraph_number', Int64), ('paragraph_length', Int64), ('tokens', List(String)), ('token_count', UInt32), ('tokens_no_stopwords', List(String)), ('token_count_no_stopwords', UInt32), ('tokens_clean', List(String)), ('token_count_clean', UInt32), ('tokens_lemma', List(String)), ('token_count_lemma', UInt32)])\n",
      "\n",
      "First few rows:\n",
      "shape: (5, 23)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† session â”† electoralT â”† firstName â”† â€¦ â”† tokens_cle â”† token_coun â”† tokens_le â”† token_cou â”‚\n",
      "â”‚ ---     â”† ---     â”† erm        â”† ---       â”†   â”† an         â”† t_clean    â”† mma       â”† nt_lemma  â”‚\n",
      "â”‚ i64     â”† i64     â”† ---        â”† str       â”†   â”† ---        â”† ---        â”† ---       â”† ---       â”‚\n",
      "â”‚         â”†         â”† i64        â”†           â”†   â”† list[str]  â”† u32        â”† list[str] â”† u32       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† [\"geehrter â”† 18         â”† [\"geehrt\" â”† 18        â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† \", \"Herr\", â”†            â”† , \"Herr\", â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† â€¦ \"begeisâ€¦ â”†            â”† â€¦ \"begeis â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”†            â”† teâ€¦       â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† []         â”† 0          â”† []        â”† 0         â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† [\"lassen\", â”† 65         â”† [\"lassen\" â”† 65        â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† \"bevor\", â€¦ â”†            â”† ,         â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† \"abgebenâ€¦  â”†            â”† \"bevor\",  â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”†            â”† â€¦         â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”†            â”† \"abgebenâ€¦ â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† [\"komme\",  â”† 29         â”† [\"kommen\" â”† 29        â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† \"SPDPartei â”†            â”† , \"SPDPar â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† vorsitzend â”†            â”† teivorsit â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”† â€¦          â”†            â”† zenâ€¦      â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† []         â”† 0          â”† []        â”† 0         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Load preprocessed data\n",
    "data_file = Path('../data/processed/df_sample_split_preprocessed.parquet')\n",
    "df = pl.read_parquet(data_file)\n",
    "\n",
    "print(f\"Preprocessed data loaded!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.schema)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49fe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens joined into full strings!\n",
      "\n",
      "Dataframe shape: (588776, 26)\n",
      "New columns: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'tokens', 'token_count', 'tokens_no_stopwords', 'token_count_no_stopwords', 'tokens_clean', 'token_count_clean', 'tokens_lemma', 'token_count_lemma', 'text_lemmatized', 'text_clean', 'text_no_stopwords']\n",
      "\n",
      "Sample text from lemmatized tokens (first paragraph):\n",
      "  geehrt Herr PrÃ¤sident Friedrich Kollegin Kollege letzter Satz Kollege Hunko begrÃ¼ÃŸen ausdrÃ¼cklich anschlieÃŸen mal Gescheit linker Ecke begeistern\n"
     ]
    }
   ],
   "source": [
    "# Join tokens back into full strings using native Polars (much faster than map_elements)\n",
    "import polars as pl\n",
    "\n",
    "# Use native Polars list.join() instead of slow map_elements\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_lemma').list.join(' ').alias('text_lemmatized')\n",
    ")\n",
    "\n",
    "# Also create versions from other token types for comparison\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_clean').list.join(' ').alias('text_clean')\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_no_stopwords').list.join(' ').alias('text_no_stopwords')\n",
    ")\n",
    "\n",
    "print(\"Tokens joined into full strings!\")\n",
    "print(f\"\\nDataframe shape: {df.shape}\")\n",
    "print(f\"New columns: {df.columns}\")\n",
    "\n",
    "print(f\"\\nSample text from lemmatized tokens (first paragraph):\")\n",
    "print(f\"  {df['text_lemmatized'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b8c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorization\n",
      "Converting lemmatized texts to TF-IDF vectors...\n",
      "Processing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588776/588776 [00:22<00:00, 25804.58doc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Vectorization complete!\n",
      "TF-IDF matrix shape: (588776, 1000)\n",
      "  Samples (documents): 588776\n",
      "  Features (vocabulary): 1000\n",
      "  Sparsity: 99.35%\n",
      "\n",
      "Vocabulary size: 1000\n",
      "Sample features: ['abgeordneter' 'abkommen' 'ablehnen' 'abschaffen' 'abschlieÃŸend'\n",
      " 'abschluss' 'absolut' 'afd' 'afghanistan' 'afrika' 'aktiv' 'aktuell'\n",
      " 'akzeptieren' 'all' 'alleine' 'alt' 'amt' 'anbieten' 'anderer'\n",
      " 'anerkennung']\n",
      "\n",
      "Top 10 TF-IDF terms for first document:\n",
      "  begrÃ¼ÃŸen: 0.3556\n",
      "  satz: 0.3313\n",
      "  geehrt herr: 0.3256\n",
      "  kollege: 0.3217\n",
      "  ausdrÃ¼cklich: 0.3020\n",
      "  mal: 0.2799\n",
      "  geehrt: 0.2726\n",
      "  herr prÃ¤sident: 0.2610\n",
      "  prÃ¤sident: 0.2518\n",
      "  letzter: 0.2338\n",
      "\n",
      "TF-IDF vectorizer and matrix ready for topic modeling!\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization of lemmatized texts\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"TF-IDF Vectorization\")\n",
    "print(\"Converting lemmatized texts to TF-IDF vectors...\")\n",
    "\n",
    "# Initialize TfidfVectorizer with German-specific parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,          # Limit vocabulary to top 1000 features\n",
    "    min_df=2,                   # Minimum document frequency\n",
    "    max_df=0.8,                 # Maximum document frequency (80% of docs)\n",
    "    ngram_range=(1, 2),         # Use unigrams and bigrams\n",
    "    sublinear_tf=True,          # Apply sublinear term frequency scaling\n",
    "    norm='l2'                   # L2 normalization\n",
    ")\n",
    "\n",
    "# Convert lemmatized texts to TF-IDF vectors\n",
    "print(\"Processing documents...\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tqdm(df['text_lemmatized'], desc=\"Vectorizing\", unit=\"doc\"))\n",
    "\n",
    "print(f\"\\nTF-IDF Vectorization complete!\")\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  Samples (documents): {tfidf_matrix.shape[0]}\")\n",
    "print(f\"  Features (vocabulary): {tfidf_matrix.shape[1]}\")\n",
    "print(f\"  Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "print(f\"\\nVocabulary size: {len(feature_names)}\")\n",
    "print(f\"Sample features: {feature_names[:20]}\")\n",
    "\n",
    "# Convert sparse matrix to dense for inspection\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Show top TF-IDF terms for first document\n",
    "print(f\"\\nTop 10 TF-IDF terms for first document:\")\n",
    "top_indices = tfidf_dense[0].argsort()[-10:][::-1]\n",
    "for idx in top_indices:\n",
    "    print(f\"  {feature_names[idx]}: {tfidf_dense[0, idx]:.4f}\")\n",
    "\n",
    "# Store TF-IDF matrix and vectorizer for later use\n",
    "print(f\"\\nTF-IDF vectorizer and matrix ready for topic modeling!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0388207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topic Modeling (FULL DATASET)\n",
      "================================================================================\n",
      "Using full dataset: 588,776 documents\n",
      "\n",
      "[STEP 1/3] Vectorizing 588,776 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588776/588776 [00:08<00:00, 68263.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Vectorization complete in 10.1s\n",
      "  Document-Term Matrix Shape: (588776, 5000)\n",
      "  Sparsity: 99.84%\n",
      "\n",
      "[STEP 2/3] Training LDA model with 15 topics...\n",
      "  This may take 10-20 minutes for 588,776 documents...\n",
      "iteration: 1 of max_iter: 15\n",
      "iteration: 2 of max_iter: 15\n",
      "iteration: 3 of max_iter: 15\n",
      "iteration: 4 of max_iter: 15\n",
      "iteration: 5 of max_iter: 15\n",
      "iteration: 6 of max_iter: 15\n",
      "iteration: 7 of max_iter: 15\n",
      "iteration: 8 of max_iter: 15\n",
      "iteration: 9 of max_iter: 15\n",
      "iteration: 10 of max_iter: 15\n",
      "iteration: 11 of max_iter: 15\n",
      "iteration: 12 of max_iter: 15\n",
      "iteration: 13 of max_iter: 15\n",
      "iteration: 14 of max_iter: 15\n",
      "iteration: 15 of max_iter: 15\n",
      "\n",
      "âœ“ LDA Training complete in 11.2 minutes\n",
      "  Perplexity: 2506.7026\n",
      "\n",
      "[STEP 3/3] Extracting topic terms...\n",
      "\n",
      "================================================================================\n",
      "TOP 15 TERMS FOR EACH TOPIC\n",
      "================================================================================\n",
      "\n",
      "Topic  1: thema, punkt, letzter, diskussion, diskutieren, sprechen, seite, woche, hÃ¶ren, rolle, fÃ¼hren, aktuell, stunde, bericht, spielen\n",
      "\n",
      "Topic  2: unternehmen, brauchen, arbeitsplatz, wirtschaft, schaffen, mensch, entwicklung, wirtschaftlich, krise, arbeitsmarkt, wachstum, beschÃ¤ftigung, mittelstand, privat, arbeitslosigkeit\n",
      "\n",
      "Topic  3: herzlich, haus, programm, sicherheit, stadt, aufmerksamkeit, zusammenarbeit, aufgabe, stelle, berlin, dank, bekÃ¤mpfung, engagement, unterstÃ¼tzen, arbeit\n",
      "\n",
      "Topic  4: schritt, kommune, ort, leisten, aufgabe, bereich, mitarbeiter, verbesserung, notwendig, brauchen, unterstÃ¼tzung, einrichtung, versorgung, hilfe, behÃ¶rde\n",
      "\n",
      "Topic  5: gesetz, bÃ¼rger, regelung, mÃ¶glichkeit, schaffen, maÃŸnahme, verbraucher, notwendig, bestehen, gesetzlich, entsprechend, klar, datum, fÃ¼hren, gelten\n",
      "\n",
      "Topic  6: deutsch, bundestag, parlament, regierung, letzter, bundeswehr, jahr, koalition, wort, gemeinsam, monat, beschlieÃŸen, entscheidung, parlamentarisch, nÃ¤chster\n",
      "\n",
      "Topic  7: weg, politik, bildung, bereich, forschung, zukunft, chance, projekt, schule, konzept, entwicklung, brauchen, setzen, gemeinsam, schreiben\n",
      "\n",
      "Topic  8: sozial, arbeit, betrieb, arbeitnehmer, hoch, ausbildung, kultur, unternehmen, bereich, arbeitgeber, arbeiten, branche, beruf, beschÃ¤ftigter, sorgen\n",
      "\n",
      "Topic  9: mensch, kind, leben, familie, jung, alt, eltern, gesellschaft, mann, jugendliche, grundgesetz, verantwortung, art, opfer, bekommen\n",
      "\n",
      "Topic 10: europÃ¤isch, union, deutsch, ziel, international, national, europa, energie, erreichen, gemeinsam, ebene, beitrag, leisten, erneuerbar, kommission\n",
      "\n",
      "Topic 11: dame, liebe, geehrt, lieb, verehrt, grÃ¼ne, fdp, spd, schÃ¶n, linke, zustimmen, reden, cducsu, danke, soldat\n",
      "\n",
      "Topic 12: europa, staat, politisch, welt, deutsch, demokratie, problem, mensch, international, lÃ¶sen, region, verantwortung, erleben, menschenrecht, situation\n",
      "\n",
      "Topic 13: frage, stellen, problem, antwort, fest, fall, genau, falsch, raum, klar, sehen, einfach, stelle, entscheidung, handeln\n",
      "\n",
      "Topic 14: euro, prozent, million, milliarde, geld, haushalt, zahl, kosten, zusÃ¤tzlich, liegen, hÃ¶he, hoch, erhÃ¶hen, verfÃ¼gung, zahlen\n",
      "\n",
      "Topic 15: vorschlag, forderung, herzlichen, gesetz, bundesland, bundesverfassungsgericht, entwurf, erklÃ¤ren, fordern, cdu, partei, erstens, urteil, bayern, grund\n",
      "\n",
      "================================================================================\n",
      "TOTAL TIME: 13.4 minutes\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LDA Topic Modeling with OPTIMIZED parameters for better coherence\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"LDA Topic Modeling (FULL DATASET)\")\n",
    "print(\"=\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "# Use FULL dataset\n",
    "SAMPLE_FRACTION = 1.0  # Use 100% of data\n",
    "if SAMPLE_FRACTION < 1.0:\n",
    "    df_lda = df.sample(fraction=SAMPLE_FRACTION, seed=42)\n",
    "    print(f\"Using {SAMPLE_FRACTION*100:.0f}% sample: {df_lda.shape[0]:,} documents\")\n",
    "else:\n",
    "    df_lda = df\n",
    "    print(f\"Using full dataset: {df_lda.shape[0]:,} documents\")\n",
    "\n",
    "# German stopwords - viel wichtiger als englische!\n",
    "german_stopwords = [\n",
    "    'der', 'die', 'das', 'den', 'dem', 'des', 'ein', 'eine', 'einer', 'einem', 'einen', 'eines',\n",
    "    'und', 'oder', 'aber', 'doch', 'wenn', 'weil', 'dass', 'ob', 'als', 'wie', 'so', 'auch',\n",
    "    'noch', 'schon', 'nur', 'sehr', 'mehr', 'viel', 'andere', 'anderen', 'anderem', 'anderer',\n",
    "    'ist', 'sind', 'war', 'waren', 'wird', 'werden', 'wurde', 'wurden', 'hat', 'haben', 'hatte', 'hatten',\n",
    "    'kann', 'kÃ¶nnen', 'konnte', 'konnten', 'muss', 'mÃ¼ssen', 'musste', 'mussten', 'soll', 'sollen',\n",
    "    'will', 'wollen', 'wollte', 'wollten', 'darf', 'dÃ¼rfen', 'mag', 'mÃ¶gen', 'mÃ¶chte', 'mÃ¶chten',\n",
    "    'ich', 'du', 'er', 'sie', 'es', 'wir', 'ihr', 'sie', 'Sie', 'mein', 'dein', 'sein', 'ihr', 'unser', 'euer',\n",
    "    'mich', 'dich', 'sich', 'uns', 'euch', 'mir', 'dir', 'ihm', 'ihr', 'ihnen', 'Ihnen',\n",
    "    'dieser', 'diese', 'dieses', 'diesem', 'diesen', 'jener', 'jene', 'jenes', 'jenem', 'jenen',\n",
    "    'welcher', 'welche', 'welches', 'welchem', 'welchen', 'was', 'wer', 'wen', 'wem', 'wessen',\n",
    "    'hier', 'dort', 'wo', 'wohin', 'woher', 'wann', 'warum', 'weshalb', 'wieso', 'nun', 'jetzt', 'dann', 'damals',\n",
    "    'immer', 'nie', 'niemals', 'manchmal', 'oft', 'selten', 'bereits', 'bisher', 'kÃ¼nftig',\n",
    "    'Ã¼ber', 'unter', 'vor', 'nach', 'zwischen', 'neben', 'bei', 'mit', 'ohne', 'fÃ¼r', 'gegen', 'durch',\n",
    "    'von', 'zu', 'bis', 'seit', 'wÃ¤hrend', 'wegen', 'trotz', 'statt', 'anstatt', 'auÃŸer', 'innerhalb', 'auÃŸerhalb',\n",
    "    'herr', 'frau', 'kollege', 'kollegin', 'kollegen', 'damen', 'herren', 'prÃ¤sident', 'prÃ¤sidentin',\n",
    "    'abgeordnete', 'abgeordneter', 'abgeordneten', 'minister', 'ministerin', 'bundesregierung',\n",
    "    'antrag', 'gesetzentwurf', 'drucksache', 'fraktion', 'ausschuss', 'debatte', 'rede',\n",
    "    'damit', 'dazu', 'davon', 'dafÃ¼r', 'dagegen', 'darauf', 'darin', 'daraus', 'darum', 'dabei',\n",
    "    'also', 'allerdings', 'jedoch', 'dennoch', 'trotzdem', 'deshalb', 'deswegen', 'daher',\n",
    "    'eigentlich', 'natÃ¼rlich', 'selbstverstÃ¤ndlich', 'tatsÃ¤chlich', 'wirklich', 'ganz', 'gar',\n",
    "    'etwa', 'ungefÃ¤hr', 'circa', 'fast', 'beinahe', 'kaum', 'eben', 'gerade', 'halt', 'mal',\n",
    "    'ja', 'nein', 'nicht', 'kein', 'keine', 'keiner', 'keinem', 'keinen', 'nichts', 'niemand',\n",
    "    'etwas', 'alles', 'alle', 'allem', 'allen', 'aller', 'jeder', 'jede', 'jedes', 'jedem', 'jeden',\n",
    "    'viele', 'vielen', 'vielem', 'vieler', 'einige', 'einigen', 'einigem', 'einiger', 'mehrere', 'mehreren',\n",
    "    'beide', 'beiden', 'beider', 'solche', 'solchen', 'solchem', 'solcher', 'welch', 'manch', 'manche',\n",
    "    'Jahr', 'Jahren', 'Prozent', 'Million', 'Millionen', 'Milliarde', 'Milliarden', 'Euro', 'Mark',\n",
    "    'heute', 'gestern', 'morgen', 'Jahr', 'Jahre', 'Monat', 'Monate', 'Woche', 'Wochen', 'Tag', 'Tage',\n",
    "    'erste', 'ersten', 'erstem', 'erster', 'zweite', 'zweiten', 'zweitem', 'zweiter', 'dritte', 'dritten',\n",
    "    'neue', 'neuen', 'neuem', 'neuer', 'neues', 'alte', 'alten', 'altem', 'alter', 'altes',\n",
    "    'groÃŸe', 'groÃŸen', 'groÃŸem', 'groÃŸer', 'groÃŸes', 'kleine', 'kleinen', 'kleinem', 'kleiner', 'kleines',\n",
    "    'gut', 'guten', 'gutem', 'guter', 'gutes', 'schlecht', 'schlechten', 'schlechtem', 'schlechter',\n",
    "    'wichtig', 'wichtigen', 'wichtigem', 'wichtiger', 'wichtiges', 'richtig', 'richtigen', 'richtigem',\n",
    "    'mÃ¶glich', 'mÃ¶glichen', 'mÃ¶glichem', 'mÃ¶glicher', 'mÃ¶gliches', 'nÃ¶tig', 'nÃ¶tigen', 'nÃ¶tigem',\n",
    "    'sagen', 'gesagt', 'sage', 'sagst', 'sagt', 'sagten', 'meinen', 'gemeint', 'meine', 'meinst', 'meint',\n",
    "    'wissen', 'gewusst', 'weiÃŸ', 'weiÃŸt', 'wisst', 'wusste', 'glauben', 'geglaubt', 'glaube', 'glaubst',\n",
    "    'denken', 'gedacht', 'denke', 'denkst', 'denkt', 'dachte', 'finden', 'gefunden', 'finde', 'findest',\n",
    "    'kommen', 'gekommen', 'komme', 'kommst', 'kommt', 'kam', 'kamen', 'gehen', 'gegangen', 'gehe', 'gehst',\n",
    "    'machen', 'gemacht', 'mache', 'machst', 'macht', 'machte', 'machten', 'tun', 'getan', 'tue', 'tust',\n",
    "    'geben', 'gegeben', 'gebe', 'gibst', 'gibt', 'gab', 'gaben', 'nehmen', 'genommen', 'nehme', 'nimmst',\n",
    "    'lassen', 'gelassen', 'lasse', 'lÃ¤sst', 'lieÃŸ', 'lieÃŸen', 'stehen', 'gestanden', 'stehe', 'stehst',\n",
    "    'bringen', 'gebracht', 'bringe', 'bringst', 'bringt', 'brachte', 'brachten',\n",
    "    'land', 'lÃ¤nder', 'deutschland', 'deutschen', 'deutscher', 'deutsche', 'bundesrepublik', 'bund', 'bundes'\n",
    "]\n",
    "\n",
    "# OPTIMIZED CountVectorizer fÃ¼r bessere Topics\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=5000,       # Mehr Features fÃ¼r bessere Unterscheidung\n",
    "    min_df=20,               # HÃ¶her: nur WÃ¶rter die in mind. 20 Docs vorkommen\n",
    "    max_df=0.7,              # Niedriger: WÃ¶rter die in >70% vorkommen raus\n",
    "    ngram_range=(1, 1),      # Nur Unigrams - Bigrams verwÃ¤ssern oft Topics\n",
    "    stop_words=german_stopwords,\n",
    "    token_pattern=r'\\b[a-zÃ¤Ã¶Ã¼ÃŸ]{3,}\\b'  # Nur WÃ¶rter mit min 3 Buchstaben\n",
    ")\n",
    "\n",
    "# STEP 1: Vectorization\n",
    "print(f\"\\n[STEP 1/3] Vectorizing {df_lda.shape[0]:,} documents...\")\n",
    "vectorize_start = time.time()\n",
    "doc_term_matrix = count_vectorizer.fit_transform(tqdm(df_lda['text_lemmatized'], desc=\"Vectorizing\"))\n",
    "vectorize_time = time.time() - vectorize_start\n",
    "\n",
    "print(f\"âœ“ Vectorization complete in {vectorize_time:.1f}s\")\n",
    "print(f\"  Document-Term Matrix Shape: {doc_term_matrix.shape}\")\n",
    "print(f\"  Sparsity: {(1 - doc_term_matrix.nnz / (doc_term_matrix.shape[0] * doc_term_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# STEP 2: LDA Training\n",
    "n_topics = 15\n",
    "print(f\"\\n[STEP 2/3] Training LDA model with {n_topics} topics...\")\n",
    "print(f\"  This may take 10-20 minutes for {df_lda.shape[0]:,} documents...\")\n",
    "\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=15,             # Reduced iterations for faster training\n",
    "    learning_method='online', # Online learning with progress\n",
    "    learning_offset=50.,\n",
    "    batch_size=4096,         # Larger batches for faster processing\n",
    "    doc_topic_prior=0.1,     # Alpha\n",
    "    topic_word_prior=0.01,   # Beta\n",
    "    n_jobs=-1,\n",
    "    verbose=1                # Shows iteration progress\n",
    ")\n",
    "\n",
    "train_start = time.time()\n",
    "lda_model.fit(doc_term_matrix)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "print(f\"\\nâœ“ LDA Training complete in {train_time/60:.1f} minutes\")\n",
    "print(f\"  Perplexity: {lda_model.perplexity(doc_term_matrix):.4f}\")\n",
    "\n",
    "# STEP 3: Extract and display topics\n",
    "print(f\"\\n[STEP 3/3] Extracting topic terms...\")\n",
    "feature_names = np.array(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 15 TERMS FOR EACH TOPIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_top_words = 15\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    print(f\"\\nTopic {topic_idx + 1:2d}: {', '.join(top_words)}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"TOTAL TIME: {total_time/60:.1f} minutes\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9db7887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967be269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL QUALITY EVALUATION\n",
      "================================================================================\n",
      "\n",
      "[1/3] Calculating Perplexity...\n",
      "âœ“ Perplexity Score: 2506.7026\n",
      "\n",
      "[2/3] Calculating Log-Likelihood...\n",
      "âœ“ Total Log-Likelihood: -39438937.7703\n",
      "âœ“ Log-Likelihood per document: -66.9846\n",
      "\n",
      "[3/3] Calculating Topic Coherence (memory-efficient)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Topics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:12<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COHERENCE SCORES BY TOPIC\n",
      "================================================================================\n",
      "  Topic  1: 0.9722\n",
      "  Topic  2: 1.3431\n",
      "  Topic  3: 0.6975\n",
      "  Topic  4: 0.9873\n",
      "  Topic  5: 1.0988\n",
      "  Topic  6: 0.9904\n",
      "  Topic  7: 1.1567\n",
      "  Topic  8: 1.1532\n",
      "  Topic  9: 1.7897\n",
      "  Topic 10: 1.2901\n",
      "  Topic 11: 1.0457\n",
      "  Topic 12: 1.1227\n",
      "  Topic 13: 0.9069\n",
      "  Topic 14: 1.6222\n",
      "  Topic 15: 0.4741\n",
      "\n",
      "================================================================================\n",
      "MODEL QUALITY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "  Number of Documents: 588,776\n",
      "  Vocabulary Size: 5,000\n",
      "  Number of Topics: 15\n",
      "\n",
      "Model Metrics:\n",
      "  Perplexity: 2506.70\n",
      "  Average Topic Coherence (PMI): 1.1100\n",
      "  Log-Likelihood: -39438937.77\n",
      "  Log-Likelihood per Doc: -66.9846\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERPLEXITY: 2506.70\n",
      "   - Measures how well the model predicts held-out data\n",
      "   - Lower is better (typical range: 100-5000 for LDA)\n",
      "   - Your score of 2507 is moderate for this dataset size\n",
      "\n",
      "ğŸ“Š TOPIC COHERENCE (PMI): 1.1100\n",
      "   - Measures how semantically related top words are within each topic\n",
      "   - Higher is better (range typically -2 to +2 for PMI)\n",
      "   - Positive values indicate words co-occur more than expected by chance\n",
      "   - Your score of 1.11 indicates good topic coherence\n",
      "\n",
      "ğŸ“Š LOG-LIKELIHOOD: -66.9846 per document\n",
      "   - Measures how well the model fits the training data\n",
      "   - Higher (less negative) is better\n",
      "\n",
      "ğŸ” OVERALL ASSESSMENT:\n",
      "   âœ“ Model shows reasonable topic structure\n",
      "   âœ“ Perplexity is within acceptable range\n",
      "\n",
      "ğŸ’¡ RECOMMENDATION:\n",
      "   For parliamentary speech analysis, consider using the ParlBERT classifier\n",
      "   (next section) for more interpretable, predefined political topic categories.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Coherence Score Berechnung (Memory-Efficient)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL QUALITY EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate Perplexity\n",
    "print(\"\\n[1/3] Calculating Perplexity...\")\n",
    "perplexity = lda_model.perplexity(doc_term_matrix)\n",
    "print(f\"âœ“ Perplexity Score: {perplexity:.4f}\")\n",
    "\n",
    "# Calculate log-likelihood\n",
    "print(\"\\n[2/3] Calculating Log-Likelihood...\")\n",
    "log_likelihood = lda_model.score(doc_term_matrix)\n",
    "log_likelihood_per_doc = log_likelihood / doc_term_matrix.shape[0]\n",
    "print(f\"âœ“ Total Log-Likelihood: {log_likelihood:.4f}\")\n",
    "print(f\"âœ“ Log-Likelihood per document: {log_likelihood_per_doc:.4f}\")\n",
    "\n",
    "# Memory-efficient coherence calculation using sparse operations\n",
    "print(\"\\n[3/3] Calculating Topic Coherence (memory-efficient)...\")\n",
    "\n",
    "def calculate_topic_coherence_sparse(lda_model, doc_term_matrix, feature_names, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate coherence using sparse matrix operations (memory-efficient)\n",
    "    Uses PMI-like measure based on co-document frequency\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csc_matrix\n",
    "    \n",
    "    # Keep matrix sparse - convert to CSC for efficient column slicing\n",
    "    dtm_sparse = csc_matrix(doc_term_matrix)\n",
    "    n_docs = dtm_sparse.shape[0]\n",
    "    \n",
    "    coherence_scores = []\n",
    "    \n",
    "    for topic_idx, topic in enumerate(tqdm(lda_model.components_, desc=\"Topics\")):\n",
    "        # Get top word indices for this topic\n",
    "        top_word_indices = topic.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        # Calculate co-occurrence coherence using document frequency\n",
    "        topic_coherence = 0\n",
    "        pair_count = 0\n",
    "        \n",
    "        for i in range(len(top_word_indices)):\n",
    "            for j in range(i + 1, len(top_word_indices)):\n",
    "                w1_idx = top_word_indices[i]\n",
    "                w2_idx = top_word_indices[j]\n",
    "                \n",
    "                # Get document frequencies (sparse column operations)\n",
    "                w1_docs = (dtm_sparse[:, w1_idx].toarray().flatten() > 0)\n",
    "                w2_docs = (dtm_sparse[:, w2_idx].toarray().flatten() > 0)\n",
    "                \n",
    "                # Co-occurrence: documents where both words appear\n",
    "                co_occur = np.sum(w1_docs & w2_docs)\n",
    "                w1_freq = np.sum(w1_docs)\n",
    "                \n",
    "                # PMI-like score: log(P(w1,w2) / P(w1))\n",
    "                if co_occur > 0 and w1_freq > 0:\n",
    "                    coherence = np.log((co_occur * n_docs) / (w1_freq * np.sum(w2_docs)) + 1e-10)\n",
    "                    topic_coherence += coherence\n",
    "                pair_count += 1\n",
    "        \n",
    "        avg_coherence = topic_coherence / pair_count if pair_count > 0 else 0\n",
    "        coherence_scores.append(avg_coherence)\n",
    "    \n",
    "    return np.mean(coherence_scores), coherence_scores\n",
    "\n",
    "# Get feature names\n",
    "feature_names = np.array(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Calculate coherence\n",
    "avg_coherence, topic_coherences = calculate_topic_coherence_sparse(lda_model, doc_term_matrix, feature_names)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COHERENCE SCORES BY TOPIC\")\n",
    "print(\"=\"*80)\n",
    "for topic_idx, coherence in enumerate(topic_coherences):\n",
    "    print(f\"  Topic {topic_idx + 1:2d}: {coherence:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL QUALITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Number of Documents: {doc_term_matrix.shape[0]:,}\")\n",
    "print(f\"  Vocabulary Size: {doc_term_matrix.shape[1]:,}\")\n",
    "print(f\"  Number of Topics: {n_topics}\")\n",
    "\n",
    "print(f\"\\nModel Metrics:\")\n",
    "print(f\"  Perplexity: {perplexity:.2f}\")\n",
    "print(f\"  Average Topic Coherence (PMI): {avg_coherence:.4f}\")\n",
    "print(f\"  Log-Likelihood: {log_likelihood:.2f}\")\n",
    "print(f\"  Log-Likelihood per Doc: {log_likelihood_per_doc:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "ğŸ“Š PERPLEXITY: {perplexity:.2f}\n",
    "   - Measures how well the model predicts held-out data\n",
    "   - Lower is better (typical range: 100-5000 for LDA)\n",
    "   - Your score of {perplexity:.0f} is {'moderate' if perplexity < 3000 else 'high'} for this dataset size\n",
    "   \n",
    "ğŸ“Š TOPIC COHERENCE (PMI): {avg_coherence:.4f}\n",
    "   - Measures how semantically related top words are within each topic\n",
    "   - Higher is better (range typically -2 to +2 for PMI)\n",
    "   - Positive values indicate words co-occur more than expected by chance\n",
    "   - Your score of {avg_coherence:.2f} indicates {'good' if avg_coherence > 0 else 'weak'} topic coherence\n",
    "   \n",
    "ğŸ“Š LOG-LIKELIHOOD: {log_likelihood_per_doc:.4f} per document\n",
    "   - Measures how well the model fits the training data\n",
    "   - Higher (less negative) is better\n",
    "   \n",
    "ğŸ” OVERALL ASSESSMENT:\n",
    "   {\"âœ“ Model shows reasonable topic structure\" if avg_coherence > 0 else \"âš  Topics may need refinement\"}\n",
    "   {\"âœ“ Perplexity is within acceptable range\" if perplexity < 4000 else \"âš  High perplexity - consider more iterations or different parameters\"}\n",
    "   \n",
    "ğŸ’¡ RECOMMENDATION:\n",
    "   For parliamentary speech analysis, consider using the ParlBERT classifier\n",
    "   (next section) for more interpretable, predefined political topic categories.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c43edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING LDA TOPIC MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. Extracting topic assignments for each document...\n",
      "Document-topic assignments shape: (588776, 17)\n",
      "Columns: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent', 'dominant_topic', 'dominant_topic_prob']\n",
      "\n",
      "First 10 rows:\n",
      "shape: (10, 17)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id      â”† session â”† electoralT â”† firstName â”† â€¦ â”† paragraph_ â”† speechCont â”† dominant_ â”† dominant_ â”‚\n",
      "â”‚ ---     â”† ---     â”† erm        â”† ---       â”†   â”† length     â”† ent        â”† topic     â”† topic_pro â”‚\n",
      "â”‚ i64     â”† i64     â”† ---        â”† str       â”†   â”† ---        â”† ---        â”† ---       â”† b         â”‚\n",
      "â”‚         â”†         â”† i64        â”†           â”†   â”† i64        â”† str        â”† i64       â”† ---       â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”†            â”†           â”† f64       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 248        â”† Sehr       â”† 5         â”† 0.327934  â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† geehrter   â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† Herr       â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† PrÃ¤sident  â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† Fâ€¦         â”†           â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 5          â”† ({0})      â”† 0         â”† 0.066667  â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 1021       â”† Aber       â”† 11        â”† 0.487377  â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† lassen Sie â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† mich,      â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† bevor wiâ€¦  â”†           â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 450        â”† Da komme   â”† 14        â”† 0.346667  â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† ich zum    â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† SPD-Partei â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† vorâ€¦       â”†           â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 5          â”† ({1})      â”† 0         â”† 0.066667  â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 583        â”† Sie finden â”† 11        â”† 0.590007  â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† auch       â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† keinerlei  â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† Unteâ€¦      â”†           â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 5          â”† ({2})      â”† 0         â”† 0.066667  â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 368        â”† Europa     â”† 11        â”† 0.40051   â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† wird doch  â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† nicht      â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† attraktâ€¦   â”†           â”†           â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 5          â”† ({3})      â”† 0         â”† 0.066667  â”‚\n",
      "â”‚ 1000550 â”† 4       â”† 19         â”† Florian   â”† â€¦ â”† 95         â”† Vielmehr   â”† 11        â”† 0.835277  â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† muss es    â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† ein Europa â”†           â”†           â”‚\n",
      "â”‚         â”†         â”†            â”†           â”†   â”†            â”† seâ€¦        â”†           â”†           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "2. Extracting top terms for each topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting topic terms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 5995.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics-terms dataframe shape: (15, 4)\n",
      "\n",
      "First 5 topics:\n",
      "shape: (5, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ topic â”† top_terms                       â”‚\n",
      "â”‚ ---   â”† ---                             â”‚\n",
      "â”‚ i64   â”† str                             â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0     â”† thema, punkt, letzter, diskussâ€¦ â”‚\n",
      "â”‚ 1     â”† unternehmen, brauchen, arbeitsâ€¦ â”‚\n",
      "â”‚ 2     â”† herzlich, haus, programm, sichâ€¦ â”‚\n",
      "â”‚ 3     â”† schritt, kommune, ort, leistenâ€¦ â”‚\n",
      "â”‚ 4     â”† gesetz, bÃ¼rger, regelung, mÃ¶glâ€¦ â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "3. Creating topic quality metrics...\n",
      "Topic metrics shape: (15, 2)\n",
      "\n",
      "Topic metrics:\n",
      "shape: (5, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ topic â”† coherence_score â”‚\n",
      "â”‚ ---   â”† ---             â”‚\n",
      "â”‚ i64   â”† f64             â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0     â”† 0.97222         â”‚\n",
      "â”‚ 1     â”† 1.343107        â”‚\n",
      "â”‚ 2     â”† 0.697478        â”‚\n",
      "â”‚ 3     â”† 0.98727         â”‚\n",
      "â”‚ 4     â”† 1.098763        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "4. Saving results to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ LDA Document-topic assignments saved (with all metadata):\n",
      "  Parquet: ..\\data\\processed\\topic_document_assignments_lda.parquet\n",
      "  CSV: ..\\data\\processed\\topic_document_assignments_lda.csv\n",
      "  Total columns: 17\n",
      "\n",
      "âœ“ LDA Topic terms saved:\n",
      "  Parquet: ..\\data\\processed\\topic_terms_lda.parquet\n",
      "  CSV: ..\\data\\processed\\topic_terms_lda.csv\n",
      "\n",
      "âœ“ LDA Topic metrics saved:\n",
      "  Parquet: ..\\data\\processed\\topic_metrics_lda.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save LDA Topic Model Results to DataFrames using Polars (with all metadata)\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING LDA TOPIC MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Get topic assignments for each document\n",
    "print(\"\\n1. Extracting topic assignments for each document...\")\n",
    "doc_topic_dist = lda_model.transform(doc_term_matrix)  # Shape: (n_docs, n_topics)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topics = doc_topic_dist.argmax(axis=1)\n",
    "dominant_topic_prob = doc_topic_dist.max(axis=1)\n",
    "\n",
    "# Get all metadata columns from original dataframe\n",
    "metadata_cols = ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', \n",
    "                 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', \n",
    "                 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent']\n",
    "df_metadata = df.select(metadata_cols)\n",
    "\n",
    "# Create Polars dataframe with document-level topic assignments and all metadata\n",
    "df_lda_topics_docs = df_metadata.with_columns(\n",
    "    pl.Series('dominant_topic', dominant_topics.tolist()),\n",
    "    pl.Series('dominant_topic_prob', dominant_topic_prob.tolist())\n",
    ")\n",
    "\n",
    "print(f\"Document-topic assignments shape: {df_lda_topics_docs.shape}\")\n",
    "print(f\"Columns: {df_lda_topics_docs.columns}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df_lda_topics_docs.head(10))\n",
    "\n",
    "# 2. Get top terms for each topic\n",
    "print(f\"\\n2. Extracting top terms for each topic...\")\n",
    "n_top_words = 15\n",
    "topics_terms_list = []\n",
    "\n",
    "for topic_idx, topic_components in enumerate(tqdm(lda_model.components_, desc=\"Extracting topic terms\")):\n",
    "    # Get indices of top words\n",
    "    top_words_idx = topic_components.argsort()[-n_top_words:][::-1]\n",
    "    \n",
    "    # Get words and their weights\n",
    "    top_words = feature_names[top_words_idx]\n",
    "    top_weights = topic_components[top_words_idx]\n",
    "    \n",
    "    topics_terms_list.append({\n",
    "        'topic': topic_idx,\n",
    "        'top_terms': ', '.join(top_words),\n",
    "        'top_terms_list': json.dumps(top_words.tolist()),\n",
    "        'weights': json.dumps(top_weights.tolist())\n",
    "    })\n",
    "\n",
    "df_lda_topics_terms = pl.DataFrame(topics_terms_list)\n",
    "\n",
    "print(f\"Topics-terms dataframe shape: {df_lda_topics_terms.shape}\")\n",
    "print(f\"\\nFirst 5 topics:\")\n",
    "print(df_lda_topics_terms.select(['topic', 'top_terms']).head())\n",
    "\n",
    "# 3. Create topic quality metrics dataframe\n",
    "print(f\"\\n3. Creating topic quality metrics...\")\n",
    "df_lda_topic_metrics = pl.DataFrame({\n",
    "    'topic': list(range(n_topics)),\n",
    "    'coherence_score': topic_coherences\n",
    "})\n",
    "\n",
    "print(f\"Topic metrics shape: {df_lda_topic_metrics.shape}\")\n",
    "print(f\"\\nTopic metrics:\")\n",
    "print(df_lda_topic_metrics.head())\n",
    "\n",
    "# 4. Save all LDA results to parquet and csv\n",
    "print(f\"\\n4. Saving results to disk...\")\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save document-topic assignments with all metadata\n",
    "parquet_path_docs = output_dir / 'topic_document_assignments_lda.parquet'\n",
    "csv_path_docs = output_dir / 'topic_document_assignments_lda.csv'\n",
    "\n",
    "df_lda_topics_docs.write_parquet(parquet_path_docs)\n",
    "df_lda_topics_docs.write_csv(csv_path_docs)\n",
    "\n",
    "print(f\"\\nâœ“ LDA Document-topic assignments saved (with all metadata):\")\n",
    "print(f\"  Parquet: {parquet_path_docs}\")\n",
    "print(f\"  CSV: {csv_path_docs}\")\n",
    "print(f\"  Total columns: {df_lda_topics_docs.width}\")\n",
    "\n",
    "# Save topic terms\n",
    "parquet_path_terms = output_dir / 'topic_terms_lda.parquet'\n",
    "csv_path_terms = output_dir / 'topic_terms_lda.csv'\n",
    "\n",
    "df_lda_topics_terms.write_parquet(parquet_path_terms)\n",
    "df_lda_topics_terms.select(['topic', 'top_terms']).write_csv(csv_path_terms)\n",
    "\n",
    "print(f\"\\nâœ“ LDA Topic terms saved:\")\n",
    "print(f\"  Parquet: {parquet_path_terms}\")\n",
    "print(f\"  CSV: {csv_path_terms}\")\n",
    "\n",
    "# Save topic metrics\n",
    "parquet_path_metrics = output_dir / 'topic_metrics_lda.parquet'\n",
    "csv_path_metrics = output_dir / 'topic_metrics_lda.csv'\n",
    "\n",
    "df_lda_topic_metrics.write_parquet(parquet_path_metrics)\n",
    "df_lda_topic_metrics.write_csv(csv_path_metrics)\n",
    "\n",
    "print(f\"\\nâœ“ LDA Topic metrics saved:\")\n",
    "print(f\"  Parquet: {parquet_path_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c40d9",
   "metadata": {},
   "source": [
    "# Alternative Topic Classification: ParlBERT-Topic-German - not applied because of time ineffectiveness\n",
    "\n",
    "The LDA topic modeling results above showed limited coherence and interpretability. The topics were not well-defined and difficult to assign meaningful labels.\n",
    "\n",
    "As an alternative, we use the **ParlBERT-Topic-German** model from HuggingFace ([chkla/parlbert-topic-german](https://huggingface.co/chkla/parlbert-topic-german)), which is a fine-tuned BERT model specifically trained for German parliamentary speech topic classification. This model classifies text into predefined political topic categories, providing more interpretable and consistent results for parliamentary speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106caac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install transformers if not already installed\n",
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a4be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARLBERT-TOPIC-GERMAN CLASSIFICATION (ONNX OPTIMIZED)\n",
      "================================================================================\n",
      "\n",
      "Loading ParlBERT-Topic-German model with ONNX optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ONNX Model loaded successfully!\n",
      "\n",
      "Available topics: ['Macroeconomics', 'Civil', 'Health', 'Agriculture', 'Labor', 'Education', 'Environment', 'Energy', 'Immigration', 'Transportation', 'Law', 'Social', 'Housing', 'Domestic', 'Defense', 'Technology', 'Foreign', 'International', 'Government', 'Public', 'Culture']\n",
      "\n",
      "Test classification:\n",
      "  Text: Das Sachgebiet Investive Ausgaben des Bundes Bundesfinanzminister Apel hat gemÃ¤ÃŸ...\n",
      "  Predicted topic: Macroeconomics\n",
      "  Confidence: 0.9967\n"
     ]
    }
   ],
   "source": [
    "# ParlBERT-Topic-German Classification (ONNX OPTIMIZED for CPU)\n",
    "# ONNX Runtime is 2-3x faster than PyTorch on CPU!\n",
    "%pip install optimum[onnxruntime] -q\n",
    "\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PARLBERT-TOPIC-GERMAN CLASSIFICATION (ONNX OPTIMIZED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load model with ONNX Runtime (much faster on CPU!)\n",
    "print(\"\\nLoading ParlBERT-Topic-German model with ONNX optimization...\")\n",
    "model_name = \"chkla/parlbert-topic-german\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# This will automatically convert to ONNX and cache it\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    export=True,  # Convert to ONNX\n",
    "    provider=\"CPUExecutionProvider\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ ONNX Model loaded successfully!\")\n",
    "\n",
    "# Get label mapping\n",
    "id2label = model.config.id2label\n",
    "print(f\"\\nAvailable topics: {list(id2label.values())}\")\n",
    "\n",
    "# Test the model\n",
    "test_text = \"Das Sachgebiet Investive Ausgaben des Bundes Bundesfinanzminister Apel hat gemÃ¤ÃŸ BMF Finanznachrichten vom 1. Januar erklÃ¤rt, die Investitionsquote des Bundes sei in den letzten zehn Jahren nahezu konstant geblieben.\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "outputs = model(**inputs)\n",
    "probs = outputs.logits.softmax(dim=-1).numpy()\n",
    "pred_id = probs.argmax()\n",
    "confidence = probs.max()\n",
    "\n",
    "print(f\"\\nTest classification:\")\n",
    "print(f\"  Text: {test_text[:80]}...\")\n",
    "print(f\"  Predicted topic: {id2label[pred_id]}\")\n",
    "print(f\"  Confidence: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ffabdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data first...\n",
      "Data loaded: 588,776 documents\n",
      "\n",
      "================================================================================\n",
      "PARLBERT CLASSIFICATION (with Stratified Sampling)\n",
      "================================================================================\n",
      "Using 10% sample: 58,877 documents\n",
      "Batch size: 32\n",
      "Total batches: 1840\n",
      "Estimated time: ~61.3 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying:   5%|â–Œ         | 95/1840 [10:53<3:20:00,  6.88s/batch, docs=3,040/58,877]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     52\u001b[39m inputs = tokenizer(\n\u001b[32m     53\u001b[39m     batch_texts,\n\u001b[32m     54\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     58\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m probs = outputs.logits.softmax(dim=-\u001b[32m1\u001b[39m).numpy()\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\optimum\\onnxruntime\\base.py:466\u001b[39m, in \u001b[36mORTSessionMixin.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\optimum\\onnxruntime\\modeling.py:1041\u001b[39m, in \u001b[36mORTModelForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, return_dict, **kwargs)\u001b[39m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1040\u001b[39m     onnx_inputs = \u001b[38;5;28mself\u001b[39m._prepare_onnx_inputs(use_torch, model_inputs)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m     onnx_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m     model_outputs = \u001b[38;5;28mself\u001b[39m._prepare_onnx_outputs(use_torch, onnx_outputs)\n\u001b[32m   1044\u001b[39m     logits = model_outputs[\u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\envs\\parl_speech\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:287\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    285\u001b[39m     output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m C.EPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Classify documents using ParlBERT (MEMORY-SAFE with Sampling)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Check if df is loaded, if not load it\n",
    "if 'df' not in dir():\n",
    "    print(\"Loading data first...\")\n",
    "    import polars as pl\n",
    "    from pathlib import Path\n",
    "    data_file = Path('../data/processed/df_sample_split_preprocessed.parquet')\n",
    "    df = pl.read_parquet(data_file)\n",
    "    print(f\"Data loaded: {df.shape[0]:,} documents\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARLBERT CLASSIFICATION (with Stratified Sampling)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# OPTION: Use sampling for faster processing\n",
    "# Set to 1.0 for full dataset, or lower (e.g., 0.1 = 10%) for faster testing\n",
    "SAMPLE_FRACTION = 0.1  # Process 10% of data (~59k documents)\n",
    "\n",
    "if SAMPLE_FRACTION < 1.0:\n",
    "    # Stratified sample by factionId to maintain party distribution\n",
    "    df_classify = df.sample(fraction=SAMPLE_FRACTION, seed=42)\n",
    "    print(f\"Using {SAMPLE_FRACTION*100:.0f}% sample: {df_classify.shape[0]:,} documents\")\n",
    "else:\n",
    "    df_classify = df\n",
    "    print(f\"Processing full dataset: {df_classify.shape[0]:,} documents\")\n",
    "\n",
    "# Get texts\n",
    "texts = df_classify['speechContent'].to_list()\n",
    "\n",
    "# Small batch size to avoid memory issues\n",
    "batch_size = 32\n",
    "total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Total batches: {total_batches}\")\n",
    "print(f\"Estimated time: ~{total_batches * 2 / 60:.1f} minutes\")\n",
    "\n",
    "# Results\n",
    "topic_labels = []\n",
    "topic_scores = []\n",
    "\n",
    "# Process in batches with memory management\n",
    "pbar = tqdm(range(0, len(texts), batch_size), desc=\"Classifying\", unit=\"batch\", total=total_batches)\n",
    "\n",
    "for i in pbar:\n",
    "    batch_texts = [t if t else \"\" for t in texts[i:i+batch_size]]\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,  # Reduced further for memory\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Inference\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs.logits.softmax(dim=-1).numpy()\n",
    "    \n",
    "    # Get predictions\n",
    "    pred_ids = probs.argmax(axis=-1)\n",
    "    confidences = probs.max(axis=-1)\n",
    "    \n",
    "    # Store results\n",
    "    topic_labels.extend([id2label[pid] for pid in pred_ids])\n",
    "    topic_scores.extend(confidences.tolist())\n",
    "    \n",
    "    # Update progress\n",
    "    pbar.set_postfix({'docs': f'{len(topic_labels):,}/{len(texts):,}'})\n",
    "    \n",
    "    # Clear memory every 100 batches\n",
    "    if i > 0 and i % 3200 == 0:\n",
    "        gc.collect()\n",
    "\n",
    "# Cleanup\n",
    "del texts\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nâœ“ Classification complete!\")\n",
    "print(f\"  Documents classified: {len(topic_labels):,}\")\n",
    "print(f\"  Average confidence: {sum(topic_scores)/len(topic_scores):.4f}\")\n",
    "\n",
    "# Store the sampled dataframe for later saving\n",
    "df_classified = df_classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff8bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOPIC DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Topic distribution:\n",
      "  Government                    :   180 documents (43.69%)\n",
      "  Civil                         :    86 documents (20.87%)\n",
      "  International                 :    22 documents ( 5.34%)\n",
      "  Law                           :    19 documents ( 4.61%)\n",
      "  Macroeconomics                :    19 documents ( 4.61%)\n",
      "  Labor                         :    16 documents ( 3.88%)\n",
      "  Social                        :    15 documents ( 3.64%)\n",
      "  Defense                       :    11 documents ( 2.67%)\n",
      "  Agriculture                   :    10 documents ( 2.43%)\n",
      "  Domestic                      :     8 documents ( 1.94%)\n",
      "  Environment                   :     7 documents ( 1.70%)\n",
      "  Technology                    :     5 documents ( 1.21%)\n",
      "  Housing                       :     4 documents ( 0.97%)\n",
      "  Health                        :     4 documents ( 0.97%)\n",
      "  Education                     :     2 documents ( 0.49%)\n",
      "  Energy                        :     2 documents ( 0.49%)\n",
      "  Foreign                       :     1 documents ( 0.24%)\n",
      "  Transportation                :     1 documents ( 0.24%)\n",
      "\n",
      "Total unique topics: 18\n"
     ]
    }
   ],
   "source": [
    "# Analyze topic distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOPIC DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get unique topics and their counts\n",
    "topic_counts = pl.DataFrame({'topic_label': topic_labels}).group_by('topic_label').len().sort('len', descending=True)\n",
    "\n",
    "print(\"\\nTopic distribution:\")\n",
    "for row in topic_counts.iter_rows(named=True):\n",
    "    percentage = (row['len'] / len(topic_labels)) * 100\n",
    "    print(f\"  {row['topic_label']:30s}: {row['len']:5d} documents ({percentage:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal unique topics: {topic_counts.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING PARLBERT TOPIC CLASSIFICATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "Document-topic assignments shape: (412, 18)\n",
      "Columns: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent', 'dominant_topic', 'dominant_topic_prob', 'topic_label']\n",
      "\n",
      "First 10 rows (selected columns):\n",
      "shape: (10, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id     â”† firstName â”† lastName â”† dominant_topic â”† topic_label â”† dominant_topic_prob â”‚\n",
      "â”‚ ---    â”† ---       â”† ---      â”† ---            â”† ---         â”† ---                 â”‚\n",
      "â”‚ i64    â”† str       â”† str      â”† i64            â”† str         â”† f64                 â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 8              â”† Government  â”† 0.942619            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 8              â”† Government  â”† 0.990203            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 13             â”† Law         â”† 0.996563            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 13             â”† Law         â”† 0.998165            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 13             â”† Law         â”† 0.970507            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 16             â”† Technology  â”† 0.606678            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 16             â”† Technology  â”† 0.622835            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 8              â”† Government  â”† 0.469457            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 16             â”† Technology  â”† 0.668161            â”‚\n",
      "â”‚ 738998 â”† burkhard  â”† lischka  â”† 1              â”† Civil       â”† 0.496788            â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Topics terms/labels dataframe shape: (18, 3)\n",
      "\n",
      "Topic mapping:\n",
      "shape: (18, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ topic â”† top_terms      â”† topic_label    â”‚\n",
      "â”‚ ---   â”† ---            â”† ---            â”‚\n",
      "â”‚ i64   â”† str            â”† str            â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0     â”† Agriculture    â”† Agriculture    â”‚\n",
      "â”‚ 1     â”† Civil          â”† Civil          â”‚\n",
      "â”‚ 2     â”† Defense        â”† Defense        â”‚\n",
      "â”‚ 3     â”† Domestic       â”† Domestic       â”‚\n",
      "â”‚ 4     â”† Education      â”† Education      â”‚\n",
      "â”‚ â€¦     â”† â€¦              â”† â€¦              â”‚\n",
      "â”‚ 13    â”† Law            â”† Law            â”‚\n",
      "â”‚ 14    â”† Macroeconomics â”† Macroeconomics â”‚\n",
      "â”‚ 15    â”† Social         â”† Social         â”‚\n",
      "â”‚ 16    â”† Technology     â”† Technology     â”‚\n",
      "â”‚ 17    â”† Transportation â”† Transportation â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Topic metrics shape: (18, 5)\n",
      "\n",
      "Topic metrics:\n",
      "shape: (18, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ topic â”† topic_label    â”† mean_confidence â”† std_confidence â”† document_count â”‚\n",
      "â”‚ ---   â”† ---            â”† ---             â”† ---            â”† ---            â”‚\n",
      "â”‚ i64   â”† str            â”† f64             â”† f64            â”† u32            â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0     â”† Agriculture    â”† 0.934629        â”† 0.131943       â”† 10             â”‚\n",
      "â”‚ 1     â”† Civil          â”† 0.606794        â”† 0.19318        â”† 86             â”‚\n",
      "â”‚ 2     â”† Defense        â”† 0.956891        â”† 0.115209       â”† 11             â”‚\n",
      "â”‚ 3     â”† Domestic       â”† 0.944106        â”† 0.077707       â”† 8              â”‚\n",
      "â”‚ 4     â”† Education      â”† 0.997873        â”† 0.000664       â”† 2              â”‚\n",
      "â”‚ â€¦     â”† â€¦              â”† â€¦               â”† â€¦              â”† â€¦              â”‚\n",
      "â”‚ 13    â”† Law            â”† 0.962178        â”† 0.062031       â”† 19             â”‚\n",
      "â”‚ 14    â”† Macroeconomics â”† 0.835497        â”† 0.168765       â”† 19             â”‚\n",
      "â”‚ 15    â”† Social         â”† 0.809505        â”† 0.220771       â”† 15             â”‚\n",
      "â”‚ 16    â”† Technology     â”† 0.694446        â”† 0.172531       â”† 5              â”‚\n",
      "â”‚ 17    â”† Transportation â”† 0.978443        â”† null           â”† 1              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Save ParlBERT Classification Results to DataFrames\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING PARLBERT TOPIC CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get all metadata columns from the CLASSIFIED dataframe (may be sampled)\n",
    "metadata_cols = ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', \n",
    "                 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', \n",
    "                 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent']\n",
    "df_metadata = df_classified.select(metadata_cols)\n",
    "\n",
    "# Create numeric topic IDs for compatibility with existing analysis\n",
    "unique_topics = sorted(list(set(topic_labels)))\n",
    "topic_to_id = {topic: idx for idx, topic in enumerate(unique_topics)}\n",
    "topic_ids = [topic_to_id[label] for label in topic_labels]\n",
    "\n",
    "# Create Polars dataframe with document-level topic assignments and all metadata\n",
    "df_topics_docs = df_metadata.with_columns(\n",
    "    pl.Series('dominant_topic', topic_ids),\n",
    "    pl.Series('dominant_topic_prob', topic_scores),\n",
    "    pl.Series('topic_label', topic_labels)\n",
    ")\n",
    "\n",
    "print(f\"\\nDocument-topic assignments shape: {df_topics_docs.shape}\")\n",
    "print(f\"Columns: {df_topics_docs.columns}\")\n",
    "print(f\"\\nFirst 10 rows (selected columns):\")\n",
    "print(df_topics_docs.select(['id', 'firstName', 'lastName', 'dominant_topic', 'topic_label', 'dominant_topic_prob']).head(10))\n",
    "\n",
    "# Create topic terms/labels dataframe (mapping topic IDs to their labels)\n",
    "df_topics_terms = pl.DataFrame({\n",
    "    'topic': list(range(len(unique_topics))),\n",
    "    'top_terms': unique_topics,  # For ParlBERT, the \"top_terms\" is the topic label itself\n",
    "    'topic_label': unique_topics\n",
    "})\n",
    "\n",
    "print(f\"\\nTopics terms/labels dataframe shape: {df_topics_terms.shape}\")\n",
    "print(f\"\\nTopic mapping:\")\n",
    "print(df_topics_terms)\n",
    "\n",
    "# Create topic metrics dataframe (confidence scores per topic)\n",
    "df_topic_stats = df_topics_docs.group_by('dominant_topic').agg([\n",
    "    pl.col('dominant_topic_prob').mean().alias('mean_confidence'),\n",
    "    pl.col('dominant_topic_prob').std().alias('std_confidence'),\n",
    "    pl.len().alias('document_count')\n",
    "]).sort('dominant_topic')\n",
    "\n",
    "# Join with topic labels\n",
    "df_topic_metrics = df_topic_stats.join(\n",
    "    df_topics_terms.select(['topic', 'topic_label']),\n",
    "    left_on='dominant_topic',\n",
    "    right_on='topic',\n",
    "    how='left'\n",
    ").select(['dominant_topic', 'topic_label', 'mean_confidence', 'std_confidence', 'document_count'])\n",
    "df_topic_metrics = df_topic_metrics.rename({'dominant_topic': 'topic'})\n",
    "\n",
    "print(f\"\\nTopic metrics shape: {df_topic_metrics.shape}\")\n",
    "print(f\"\\nTopic metrics:\")\n",
    "print(df_topic_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72413d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ BERT Document-topic assignments saved (with all metadata):\n",
      "  Parquet: ..\\data\\processed\\topic_document_assignments_bert.parquet\n",
      "  CSV: ..\\data\\processed\\topic_document_assignments_bert.csv\n",
      "  Total columns: 18\n",
      "\n",
      "âœ“ BERT Topic terms/labels saved:\n",
      "  Parquet: ..\\data\\processed\\topic_terms_bert.parquet\n",
      "  CSV: ..\\data\\processed\\topic_terms_bert.csv\n",
      "\n",
      "âœ“ BERT Topic metrics saved:\n",
      "  Parquet: ..\\data\\processed\\topic_metrics_bert.parquet\n",
      "  CSV: ..\\data\\processed\\topic_metrics_bert.csv\n",
      "\n",
      "================================================================================\n",
      "PARLBERT TOPIC CLASSIFICATION RESULTS SAVED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save all BERT results to parquet and csv\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save document-topic assignments with all metadata (main result for merging)\n",
    "parquet_path_docs = output_dir / 'topic_document_assignments_bert.parquet'\n",
    "csv_path_docs = output_dir / 'topic_document_assignments_bert.csv'\n",
    "\n",
    "df_topics_docs.write_parquet(parquet_path_docs)\n",
    "df_topics_docs.write_csv(csv_path_docs)\n",
    "\n",
    "print(f\"\\nâœ“ BERT Document-topic assignments saved (with all metadata):\")\n",
    "print(f\"  Parquet: {parquet_path_docs}\")\n",
    "print(f\"  CSV: {csv_path_docs}\")\n",
    "print(f\"  Total columns: {df_topics_docs.width}\")\n",
    "\n",
    "# Save topic terms/labels\n",
    "parquet_path_terms = output_dir / 'topic_terms_bert.parquet'\n",
    "csv_path_terms = output_dir / 'topic_terms_bert.csv'\n",
    "\n",
    "df_topics_terms.write_parquet(parquet_path_terms)\n",
    "df_topics_terms.write_csv(csv_path_terms)\n",
    "\n",
    "print(f\"\\nâœ“ BERT Topic terms/labels saved:\")\n",
    "print(f\"  Parquet: {parquet_path_terms}\")\n",
    "print(f\"  CSV: {csv_path_terms}\")\n",
    "\n",
    "# Save topic metrics\n",
    "parquet_path_metrics = output_dir / 'topic_metrics_bert.parquet'\n",
    "csv_path_metrics = output_dir / 'topic_metrics_bert.csv'\n",
    "\n",
    "df_topic_metrics.write_parquet(parquet_path_metrics)\n",
    "df_topic_metrics.write_csv(csv_path_metrics)\n",
    "\n",
    "print(f\"\\nâœ“ BERT Topic metrics saved:\")\n",
    "print(f\"  Parquet: {parquet_path_metrics}\")\n",
    "print(f\"  CSV: {csv_path_metrics}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"PARLBERT TOPIC CLASSIFICATION RESULTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parl_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
