{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885e85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "✓ Loaded df_sample_sentiment.parquet: (5887, 19)\n",
      "✓ Sentiment data already contains topic assignments from LDA modeling\n",
      "\n",
      "Dataframes loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "\n",
    "# Define paths\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "# Load sentiment data (which was created from LDA topics)\n",
    "df_sentiment = pl.read_parquet(processed_dir / 'df_sample_sentiment.parquet')\n",
    "print(f\"✓ Loaded df_sample_sentiment.parquet: {df_sentiment.shape}\")\n",
    "\n",
    "# NOTE: Sentiment was analyzed on LDA data, so all topic info is already included\n",
    "# No need to load separate topic file - sentiment df already has everything!\n",
    "print(f\"✓ Sentiment data already contains topic assignments from LDA modeling\")\n",
    "\n",
    "print(f\"\\nDataframes loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32bd5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA PREPARATION\n",
      "================================================================================\n",
      "\n",
      "Sentiment dataframe columns:\n",
      "  ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent', 'dominant_topic', 'dominant_topic_prob', 'sentiment_class', 'sentiment_probabilities']\n",
      "\n",
      "Adding unique ID to sentiment dataframe...\n",
      "✓ Created unique_id in sentiment data\n",
      "  Shape: (5887, 20)\n",
      "  Sample IDs: shape: (5, 1)\n",
      "┌───────────┐\n",
      "│ unique_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "│ 670669_17 │\n",
      "│ 698691_3  │\n",
      "│ 690973_6  │\n",
      "│ 781601_24 │\n",
      "│ 661773_2  │\n",
      "└───────────┘\n",
      "\n",
      "================================================================================\n",
      "DATA READY FOR FINAL PROCESSING!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create common ID from speech ID and paragraph ID\n",
    "print(\"=\"*80)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check columns in sentiment dataframe\n",
    "print(\"\\nSentiment dataframe columns:\")\n",
    "print(f\"  {df_sentiment.columns}\")\n",
    "\n",
    "# Create unique ID for reference\n",
    "print(\"\\nAdding unique ID to sentiment dataframe...\")\n",
    "df_sentiment = df_sentiment.with_columns(\n",
    "    pl.concat_str(\n",
    "        pl.col('id').cast(pl.Utf8),\n",
    "        pl.lit('_'),\n",
    "        pl.col('paragraph_number').cast(pl.Utf8)\n",
    "    ).alias('unique_id')\n",
    ")\n",
    "print(f\"✓ Created unique_id in sentiment data\")\n",
    "print(f\"  Shape: {df_sentiment.shape}\")\n",
    "print(f\"  Sample IDs: {df_sentiment.select('unique_id').head(5)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"DATA READY FOR FINAL PROCESSING!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71165dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY CHECK\n",
      "================================================================================\n",
      "\n",
      "Sentiment data with LDA topics:\n",
      "  Total rows: 5887\n",
      "  Unique IDs: 5887\n",
      "  Columns: 20\n",
      "\n",
      "Missing values in key columns:\n",
      "  sentiment_class: 0\n",
      "  dominant_topic: 0\n",
      "  speechContent: 0\n",
      "  factionId: 0\n",
      "\n",
      "✓ Data quality check complete!\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check\n",
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSentiment data with LDA topics:\")\n",
    "print(f\"  Total rows: {df_sentiment.shape[0]}\")\n",
    "print(f\"  Unique IDs: {df_sentiment['unique_id'].n_unique()}\")\n",
    "print(f\"  Columns: {len(df_sentiment.columns)}\")\n",
    "\n",
    "# Check for any missing values in key columns\n",
    "print(f\"\\nMissing values in key columns:\")\n",
    "print(f\"  sentiment_class: {df_sentiment['sentiment_class'].null_count()}\")\n",
    "print(f\"  dominant_topic: {df_sentiment['dominant_topic'].null_count()}\")\n",
    "print(f\"  speechContent: {df_sentiment['speechContent'].null_count()}\")\n",
    "print(f\"  factionId: {df_sentiment['factionId'].null_count()}\")\n",
    "\n",
    "print(f\"\\n✓ Data quality check complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd54e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING FINAL ANALYSIS DATAFRAME\n",
      "================================================================================\n",
      "\n",
      "1. Preparing final dataframe...\n",
      "✓ Data ready: (5887, 20)\n",
      "\n",
      "2. Formatting final analysis dataframe...\n",
      "✓ Final dataframe created!\n",
      "  Shape: (5887, 8)\n",
      "  Columns: ['time', 'speaker', 'party', 'speech', 'topic', 'topic_confidence', 'sentiment', 'unique_id']\n",
      "\n",
      "================================================================================\n",
      "FINAL DATAFRAME PREVIEW\n",
      "================================================================================\n",
      "shape: (10, 8)\n",
      "┌──────────────┬──────────────┬───────┬──────────────┬───────┬─────────────┬───────────┬───────────┐\n",
      "│ time         ┆ speaker      ┆ party ┆ speech       ┆ topic ┆ topic_confi ┆ sentiment ┆ unique_id │\n",
      "│ ---          ┆ ---          ┆ ---   ┆ ---          ┆ ---   ┆ dence       ┆ ---       ┆ ---       │\n",
      "│ str          ┆ str          ┆ i64   ┆ str          ┆ str   ┆ ---         ┆ str       ┆ str       │\n",
      "│              ┆              ┆       ┆              ┆       ┆ f64         ┆           ┆           │\n",
      "╞══════════════╪══════════════╪═══════╪══════════════╪═══════╪═════════════╪═══════════╪═══════════╡\n",
      "│ 2005-01-20T0 ┆ Peter H      ┆ 4     ┆ der im Globa ┆ 9     ┆ 0.599983    ┆ neutral   ┆ 670669_17 │\n",
      "│ 0:00:00.0000 ┆ Carstensen   ┆       ┆ lisierungspr ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ ozess …      ┆       ┆             ┆           ┆           │\n",
      "│ 2007-05-24T0 ┆ Heinz        ┆ 23    ┆ Die          ┆ 11    ┆ 0.443735    ┆ neutral   ┆ 698691_3  │\n",
      "│ 0:00:00.0000 ┆ Schmitt      ┆       ┆ Schönheit    ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ der Erde und ┆       ┆             ┆           ┆           │\n",
      "│              ┆              ┆       ┆ die…         ┆       ┆             ┆           ┆           │\n",
      "│ 2006-11-22T0 ┆ Peter Struck ┆ 23    ┆ ({1})        ┆ 0     ┆ 0.066667    ┆ positive  ┆ 690973_6  │\n",
      "│ 0:00:00.0000 ┆              ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 2012-11-29T0 ┆ Ingrid       ┆ 4     ┆ ({10})       ┆ 0     ┆ 0.066667    ┆ positive  ┆ 781601_24 │\n",
      "│ 0:00:00.0000 ┆ Fischbach    ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 2004-05-07T0 ┆ hans-werner  ┆ 23    ┆ großartige   ┆ 7     ┆ 0.429239    ┆ neutral   ┆ 661773_2  │\n",
      "│ 0:00:00.0000 ┆ bertl        ┆       ┆ Gemeinschaft ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ sleistu…     ┆       ┆             ┆           ┆           │\n",
      "│ 2006-12-13T0 ┆ Siegfried    ┆ 4     ┆ Dann kommen  ┆ 0     ┆ 0.38522     ┆ neutral   ┆ 692334_12 │\n",
      "│ 0:00:00.0000 ┆ Kauder       ┆       ┆ wir zum      ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ strafproze…  ┆       ┆             ┆           ┆           │\n",
      "│ 2011-02-10T0 ┆ Dorothee Bär ┆ 4     ┆ ({9})        ┆ 0     ┆ 0.066667    ┆ positive  ┆ 751068_21 │\n",
      "│ 0:00:00.0000 ┆              ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆              ┆       ┆             ┆           ┆           │\n",
      "│ 2011-04-14T0 ┆ Ingrid       ┆ 23    ┆ Das ist das  ┆ 12    ┆ 0.345851    ┆ negative  ┆ 755062_18 │\n",
      "│ 0:00:00.0000 ┆ Arndt-Brauer ┆       ┆ Problem. Die ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ aktue…       ┆       ┆             ┆           ┆           │\n",
      "│ 2015-12-04T0 ┆ lothar       ┆ 23    ┆ Da wir und   ┆ 4     ┆ 0.315121    ┆ negative  ┆ 824478_10 │\n",
      "│ 0:00:00.0000 ┆ binding      ┆       ┆ auch das BMF ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ offens…      ┆       ┆             ┆           ┆           │\n",
      "│ 2000-03-16T0 ┆ Eckhardt     ┆ 23    ┆ Ich werde    ┆ 9     ┆ 0.275697    ┆ neutral   ┆ 607611_9  │\n",
      "│ 0:00:00.0000 ┆ Barthel      ┆       ┆ Ihnen anhand ┆       ┆             ┆           ┆           │\n",
      "│ 00           ┆              ┆       ┆ eines k…     ┆       ┆             ┆           ┆           │\n",
      "└──────────────┴──────────────┴───────┴──────────────┴───────┴─────────────┴───────────┴───────────┘\n",
      "\n",
      "================================================================================\n",
      "LDA TOPIC DISTRIBUTION\n",
      "================================================================================\n",
      "  Topic 0  :  2281 speeches (38.75%)\n",
      "  Topic 13 :   379 speeches ( 6.44%)\n",
      "  Topic 4  :   371 speeches ( 6.30%)\n",
      "  Topic 11 :   365 speeches ( 6.20%)\n",
      "  Topic 12 :   319 speeches ( 5.42%)\n",
      "  Topic 14 :   281 speeches ( 4.77%)\n",
      "  Topic 10 :   267 speeches ( 4.54%)\n",
      "  Topic 8  :   259 speeches ( 4.40%)\n",
      "  Topic 5  :   243 speeches ( 4.13%)\n",
      "  Topic 9  :   242 speeches ( 4.11%)\n",
      "  Topic 6  :   207 speeches ( 3.52%)\n",
      "  Topic 1  :   204 speeches ( 3.47%)\n",
      "  Topic 3  :   180 speeches ( 3.06%)\n",
      "  Topic 7  :   150 speeches ( 2.55%)\n",
      "  Topic 2  :   139 speeches ( 2.36%)\n",
      "\n",
      "✓ Final dataframe saved:\n",
      "  Parquet: ..\\data\\processed\\df_final_analysis.parquet\n",
      "  CSV: ..\\data\\processed\\df_final_analysis.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL ANALYSIS DATAFRAME CREATED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create final analysis dataframe with LDA topics\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING FINAL ANALYSIS DATAFRAME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# No merging needed - sentiment data already has LDA topics!\n",
    "# Just need to format and select the relevant columns\n",
    "print(\"\\n1. Preparing final dataframe...\")\n",
    "df_merged = df_sentiment  # Already has everything we need\n",
    "\n",
    "print(f\"✓ Data ready: {df_merged.shape}\")\n",
    "\n",
    "# Create final dataframe with relevant columns\n",
    "print(\"\\n2. Formatting final analysis dataframe...\")\n",
    "\n",
    "# Combine first and last name for speaker column\n",
    "df_final = df_merged.with_columns([\n",
    "    pl.concat_str([pl.col('firstName'), pl.lit(' '), pl.col('lastName')]).alias('speaker')\n",
    "])\n",
    "\n",
    "# Select and rename columns for final output\n",
    "df_final = df_final.select([\n",
    "    pl.col('date').alias('time'),\n",
    "    pl.col('speaker'),\n",
    "    pl.col('factionId').alias('party'),\n",
    "    pl.col('speechContent').alias('speech'),\n",
    "    pl.col('dominant_topic').cast(pl.Utf8).alias('topic'),  # LDA topic number\n",
    "    pl.col('dominant_topic_prob').alias('topic_confidence'),\n",
    "    pl.col('sentiment_class').alias('sentiment'),\n",
    "    pl.col('unique_id')\n",
    "])\n",
    "\n",
    "print(f\"✓ Final dataframe created!\")\n",
    "print(f\"  Shape: {df_final.shape}\")\n",
    "print(f\"  Columns: {df_final.columns}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL DATAFRAME PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(df_final.head(10))\n",
    "\n",
    "# Show topic distribution\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"LDA TOPIC DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "topic_dist = df_final.group_by('topic').len().sort('len', descending=True)\n",
    "for row in topic_dist.iter_rows(named=True):\n",
    "    percentage = (row['len'] / df_final.shape[0]) * 100\n",
    "    print(f\"  Topic {row['topic']:3s}: {row['len']:5d} speeches ({percentage:5.2f}%)\")\n",
    "\n",
    "# Save final dataframe\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "parquet_path = output_dir / 'df_final_analysis.parquet'\n",
    "csv_path = output_dir / 'df_final_analysis.csv'\n",
    "\n",
    "df_final.write_parquet(parquet_path)\n",
    "df_final.write_csv(csv_path)\n",
    "\n",
    "print(f\"\\n✓ Final dataframe saved:\")\n",
    "print(f\"  Parquet: {parquet_path}\")\n",
    "print(f\"  CSV: {csv_path}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANALYSIS DATAFRAME CREATED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parl_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
