{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "885e85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "✓ Loaded df_sample_sentiment.parquet: (412, 18)\n",
      "✓ Loaded topic_document_assignments.parquet: (412, 17)\n",
      "\n",
      "Dataframes loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "\n",
    "# Define paths\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "# Load sentiment data\n",
    "df_sentiment = pl.read_parquet(processed_dir / 'df_sample_sentiment.parquet')\n",
    "print(f\"✓ Loaded df_sample_sentiment.parquet: {df_sentiment.shape}\")\n",
    "\n",
    "# Load topic data with document assignments (includes all metadata)\n",
    "df_topic = pl.read_parquet(processed_dir / 'topic_document_assignments.parquet')\n",
    "print(f\"✓ Loaded topic_document_assignments.parquet: {df_topic.shape}\")\n",
    "\n",
    "print(f\"\\nDataframes loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b32bd5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING COMMON IDENTIFIERS\n",
      "================================================================================\n",
      "\n",
      "Sentiment dataframe columns:\n",
      "  ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'word_count', 'sentiment_class', 'sentiment_probabilities']\n",
      "\n",
      "Topic dataframe columns:\n",
      "  ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'speechContent', 'dominant_topic', 'dominant_topic_prob']\n",
      "\n",
      "1. Adding common ID to sentiment dataframe...\n",
      "✓ Created unique_id in sentiment data\n",
      "  Shape: (412, 19)\n",
      "  Sample IDs: shape: (5, 1)\n",
      "┌───────────┐\n",
      "│ unique_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "│ 738998_1  │\n",
      "│ 738998_2  │\n",
      "│ 738998_3  │\n",
      "│ 738998_4  │\n",
      "│ 738998_5  │\n",
      "└───────────┘\n",
      "\n",
      "2. Adding common ID to topic dataframe...\n",
      "✓ Created unique_id in topic data\n",
      "  Shape: (412, 18)\n",
      "  Sample IDs: shape: (5, 1)\n",
      "┌───────────┐\n",
      "│ unique_id │\n",
      "│ ---       │\n",
      "│ str       │\n",
      "╞═══════════╡\n",
      "│ 738998_1  │\n",
      "│ 738998_2  │\n",
      "│ 738998_3  │\n",
      "│ 738998_4  │\n",
      "│ 738998_5  │\n",
      "└───────────┘\n",
      "\n",
      "================================================================================\n",
      "COMMON IDENTIFIERS CREATED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create common ID from speech ID and paragraph ID\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING COMMON IDENTIFIERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check columns in both dataframes\n",
    "print(\"\\nSentiment dataframe columns:\")\n",
    "print(f\"  {df_sentiment.columns}\")\n",
    "\n",
    "print(\"\\nTopic dataframe columns:\")\n",
    "print(f\"  {df_topic.columns}\")\n",
    "\n",
    "# Create common ID in sentiment dataframe\n",
    "print(\"\\n1. Adding common ID to sentiment dataframe...\")\n",
    "df_sentiment = df_sentiment.with_columns(\n",
    "    pl.concat_str(\n",
    "        pl.col('id').cast(pl.Utf8),\n",
    "        pl.lit('_'),\n",
    "        pl.col('paragraph_number').cast(pl.Utf8)\n",
    "    ).alias('unique_id')\n",
    ")\n",
    "print(f\"✓ Created unique_id in sentiment data\")\n",
    "print(f\"  Shape: {df_sentiment.shape}\")\n",
    "print(f\"  Sample IDs: {df_sentiment.select('unique_id').head(5)}\")\n",
    "\n",
    "# Create common ID in topic dataframe\n",
    "print(\"\\n2. Adding common ID to topic dataframe...\")\n",
    "df_topic = df_topic.with_columns(\n",
    "    pl.concat_str(\n",
    "        pl.col('id').cast(pl.Utf8),\n",
    "        pl.lit('_'),\n",
    "        pl.col('paragraph_number').cast(pl.Utf8)\n",
    "    ).alias('unique_id')\n",
    ")\n",
    "print(f\"✓ Created unique_id in topic data\")\n",
    "print(f\"  Shape: {df_topic.shape}\")\n",
    "print(f\"  Sample IDs: {df_topic.select('unique_id').head(5)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COMMON IDENTIFIERS CREATED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd54e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CALCULATING AVERAGE SENTIMENT PER TOPIC\n",
      "================================================================================\n",
      "\n",
      "1. Merging sentiment and topic data...\n",
      "✓ Merged data shape: (412, 21)\n",
      "  Columns: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'word_count', 'sentiment_class', 'sentiment_probabilities', 'unique_id', 'dominant_topic', 'dominant_topic_prob']\n",
      "\n",
      "2. Creating sentiment score column...\n",
      "✓ Added sentiment_score\n",
      "\n",
      "3. Calculating average sentiment metrics per topic...\n",
      "\n",
      "✓ Sentiment by topic calculated!\n",
      "  Shape: (23, 7)\n",
      "\n",
      "Average sentiment per topic:\n",
      "shape: (23, 7)\n",
      "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ dominant_top ┆ avg_sentime ┆ avg_topic_p ┆ paragraph_c ┆ positive_co ┆ neutral_cou ┆ negative_co │\n",
      "│ ic           ┆ nt_score    ┆ robability  ┆ ount        ┆ unt         ┆ nt          ┆ unt         │\n",
      "│ ---          ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
      "│ i64          ┆ f64         ┆ f64         ┆ u32         ┆ u32         ┆ u32         ┆ u32         │\n",
      "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 0            ┆ 0.652482    ┆ 0.033333    ┆ 141         ┆ 104         ┆ 25          ┆ 12          │\n",
      "│ 1            ┆ -0.25       ┆ 0.559921    ┆ 4           ┆ 0           ┆ 3           ┆ 1           │\n",
      "│ 2            ┆ 0.0         ┆ 0.49213     ┆ 3           ┆ 0           ┆ 3           ┆ 0           │\n",
      "│ 3            ┆ -0.131579   ┆ 0.547502    ┆ 38          ┆ 0           ┆ 33          ┆ 5           │\n",
      "│ 4            ┆ -0.117647   ┆ 0.58443     ┆ 17          ┆ 0           ┆ 15          ┆ 2           │\n",
      "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
      "│ 21           ┆ 0.0         ┆ 0.503366    ┆ 9           ┆ 0           ┆ 9           ┆ 0           │\n",
      "│ 23           ┆ -0.058824   ┆ 0.650083    ┆ 17          ┆ 0           ┆ 16          ┆ 1           │\n",
      "│ 25           ┆ 0.0         ┆ 0.45585     ┆ 3           ┆ 0           ┆ 3           ┆ 0           │\n",
      "│ 26           ┆ 0.0         ┆ 0.721041    ┆ 9           ┆ 0           ┆ 9           ┆ 0           │\n",
      "│ 29           ┆ -0.078947   ┆ 0.613331    ┆ 38          ┆ 1           ┆ 33          ┆ 4           │\n",
      "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n",
      "\n",
      "✓ Results saved:\n",
      "  Parquet: ..\\data\\processed\\sentiment_by_topic.parquet\n",
      "  CSV: ..\\data\\processed\\sentiment_by_topic.csv\n",
      "\n",
      "================================================================================\n",
      "SENTIMENT BY TOPIC ANALYSIS COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate average sentiment per topic\n",
    "print(\"=\"*80)\n",
    "print(\"CALCULATING AVERAGE SENTIMENT PER TOPIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# First, merge sentiment and topic data on unique_id\n",
    "print(\"\\n1. Merging sentiment and topic data...\")\n",
    "df_merged = df_sentiment.join(\n",
    "    df_topic.select(['unique_id', 'dominant_topic', 'dominant_topic_prob']),\n",
    "    on='unique_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"✓ Merged data shape: {df_merged.shape}\")\n",
    "print(f\"  Columns: {df_merged.columns}\")\n",
    "\n",
    "# Create sentiment score mapping\n",
    "sentiment_score_map = {\n",
    "    'positive': 1,\n",
    "    'neutral': 0,\n",
    "    'negative': -1\n",
    "}\n",
    "\n",
    "# Add sentiment score column\n",
    "print(\"\\n2. Creating sentiment score column...\")\n",
    "df_merged = df_merged.with_columns(\n",
    "    pl.col('sentiment_class').map_elements(\n",
    "        lambda x: sentiment_score_map.get(x, 0),\n",
    "        return_dtype=pl.Int32\n",
    "    ).alias('sentiment_score')\n",
    ")\n",
    "\n",
    "print(f\"✓ Added sentiment_score\")\n",
    "\n",
    "# Calculate average sentiment per topic\n",
    "print(\"\\n3. Calculating average sentiment metrics per topic...\")\n",
    "sentiment_by_topic = df_merged.group_by('dominant_topic').agg([\n",
    "    pl.col('sentiment_score').mean().alias('avg_sentiment_score'),\n",
    "    pl.col('dominant_topic_prob').mean().alias('avg_topic_probability'),\n",
    "    pl.len().alias('paragraph_count'),\n",
    "    (pl.col('sentiment_class') == 'positive').sum().alias('positive_count'),\n",
    "    (pl.col('sentiment_class') == 'neutral').sum().alias('neutral_count'),\n",
    "    (pl.col('sentiment_class') == 'negative').sum().alias('negative_count')\n",
    "]).sort('dominant_topic')\n",
    "\n",
    "print(f\"\\n✓ Sentiment by topic calculated!\")\n",
    "print(f\"  Shape: {sentiment_by_topic.shape}\")\n",
    "print(f\"\\nAverage sentiment per topic:\")\n",
    "print(sentiment_by_topic)\n",
    "\n",
    "# Save results\n",
    "output_dir = Path('../data/processed')\n",
    "sentiment_by_topic_path = output_dir / 'sentiment_by_topic.parquet'\n",
    "sentiment_by_topic.write_parquet(sentiment_by_topic_path)\n",
    "\n",
    "sentiment_by_topic_csv = output_dir / 'sentiment_by_topic.csv'\n",
    "sentiment_by_topic.write_csv(sentiment_by_topic_csv)\n",
    "\n",
    "print(f\"\\n✓ Results saved:\")\n",
    "print(f\"  Parquet: {sentiment_by_topic_path}\")\n",
    "print(f\"  CSV: {sentiment_by_topic_csv}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SENTIMENT BY TOPIC ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parl_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
