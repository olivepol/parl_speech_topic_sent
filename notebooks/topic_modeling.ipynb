{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6035ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data loaded!\n",
      "Shape: (412, 23)\n",
      "\n",
      "Column names: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'tokens', 'token_count', 'tokens_no_stopwords', 'token_count_no_stopwords', 'tokens_clean', 'token_count_clean', 'tokens_lemma', 'token_count_lemma']\n",
      "\n",
      "Data types:\n",
      "Schema([('id', Int64), ('session', Int64), ('electoralTerm', Int64), ('firstName', String), ('lastName', String), ('politicianId', Int64), ('speechContent', String), ('factionId', Int64), ('documentUrl', String), ('positionShort', String), ('positionLong', String), ('date', String), ('speech_length', Int64), ('paragraph_number', Int64), ('paragraph_length', Int64), ('tokens', List(String)), ('token_count', UInt32), ('tokens_no_stopwords', List(String)), ('token_count_no_stopwords', UInt32), ('tokens_clean', List(String)), ('token_count_clean', UInt32), ('tokens_lemma', List(String)), ('token_count_lemma', UInt32)])\n",
      "\n",
      "First few rows:\n",
      "shape: (5, 23)\n",
      "┌────────┬─────────┬────────────┬───────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
      "│ id     ┆ session ┆ electoralT ┆ firstName ┆ … ┆ tokens_cle ┆ token_coun ┆ tokens_lem ┆ token_cou │\n",
      "│ ---    ┆ ---     ┆ erm        ┆ ---       ┆   ┆ an         ┆ t_clean    ┆ ma         ┆ nt_lemma  │\n",
      "│ i64    ┆ i64     ┆ ---        ┆ str       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n",
      "│        ┆         ┆ i64        ┆           ┆   ┆ list[str]  ┆ u32        ┆ list[str]  ┆ u32       │\n",
      "╞════════╪═════════╪════════════╪═══════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
      "│ 738998 ┆ 43      ┆ 17         ┆ burkhard  ┆ … ┆ [\"Frau\",   ┆ 5          ┆ [\"Frau\",   ┆ 5         │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"Präsident ┆            ┆ \"Präsident ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ in\", …     ┆            ┆ in\", …     ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"Her…      ┆            ┆ \"Her…      ┆           │\n",
      "│ 738998 ┆ 43      ┆ 17         ┆ burkhard  ┆ … ┆ [\"Kollege\" ┆ 16         ┆ [\"Kollege\" ┆ 16        │\n",
      "│        ┆         ┆            ┆           ┆   ┆ , \"Hevelin ┆            ┆ , \"Hevelin ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ g\", …      ┆            ┆ g\", …      ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"bes…      ┆            ┆ \"bes…      ┆           │\n",
      "│ 738998 ┆ 43      ┆ 17         ┆ burkhard  ┆ … ┆ [\"Anlass\", ┆ 33         ┆ [\"Anlass\", ┆ 33        │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"heutige\", ┆            ┆ \"heutig\",  ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ … \"stärk…  ┆            ┆ … \"stärke… ┆           │\n",
      "│ 738998 ┆ 43      ┆ 17         ┆ burkhard  ┆ … ┆ [\"Zahlen\", ┆ 17         ┆ [\"Zahl\",   ┆ 17        │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"wissen\",  ┆            ┆ \"wissen\",  ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ … \"extrem… ┆            ┆ …          ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆            ┆            ┆ \"extrem\"]  ┆           │\n",
      "│ 738998 ┆ 43      ┆ 17         ┆ burkhard  ┆ … ┆ [\"Ermittlu ┆ 11         ┆ [\"Ermittlu ┆ 11        │\n",
      "│        ┆         ┆            ┆           ┆   ┆ ngsstelle\" ┆            ┆ ngsstelle\" ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ ,          ┆            ┆ ,          ┆           │\n",
      "│        ┆         ┆            ┆           ┆   ┆ \"Kinderp…  ┆            ┆ \"Kinderp…  ┆           │\n",
      "└────────┴─────────┴────────────┴───────────┴───┴────────────┴────────────┴────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Load preprocessed data\n",
    "data_file = Path('../data/processed/df_sample_split_preprocessed_topic.parquet')\n",
    "df = pl.read_parquet(data_file)\n",
    "\n",
    "print(f\"Preprocessed data loaded!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.schema)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens joined into full strings!\n",
      "\n",
      "Dataframe shape: (412, 26)\n",
      "New columns: ['id', 'session', 'electoralTerm', 'firstName', 'lastName', 'politicianId', 'speechContent', 'factionId', 'documentUrl', 'positionShort', 'positionLong', 'date', 'speech_length', 'paragraph_number', 'paragraph_length', 'tokens', 'token_count', 'tokens_no_stopwords', 'token_count_no_stopwords', 'tokens_clean', 'token_count_clean', 'tokens_lemma', 'token_count_lemma', 'text_lemmatized', 'text_clean', 'text_no_stopwords']\n",
      "\n",
      "Sample text from lemmatized tokens (first paragraph):\n",
      "  Frau Präsidentin Dame Herr Herr\n",
      "\n",
      "Sample text from clean tokens (first paragraph):\n",
      "  Frau Präsidentin Damen Herren Herr\n"
     ]
    }
   ],
   "source": [
    "# Join tokens back into full strings\n",
    "import polars as pl\n",
    "\n",
    "# Create a function to join tokens\n",
    "def join_tokens(tokens):\n",
    "    \"\"\"Join a list of tokens into a single string.\"\"\"\n",
    "    if tokens is None or len(tokens) == 0:\n",
    "        return \"\"\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply to create text from lemmatized tokens\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_lemma').map_elements(join_tokens, return_dtype=pl.Utf8).alias('text_lemmatized')\n",
    ")\n",
    "\n",
    "# Also create versions from other token types for comparison\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_clean').map_elements(join_tokens, return_dtype=pl.Utf8).alias('text_clean')\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col('tokens_no_stopwords').map_elements(join_tokens, return_dtype=pl.Utf8).alias('text_no_stopwords')\n",
    ")\n",
    "\n",
    "print(\"Tokens joined into full strings!\")\n",
    "print(f\"\\nDataframe shape: {df.shape}\")\n",
    "print(f\"New columns: {df.columns}\")\n",
    "\n",
    "print(f\"\\nSample text from lemmatized tokens (first paragraph):\")\n",
    "print(f\"  {df['text_lemmatized'][0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b8c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorization\n",
      "Converting lemmatized texts to TF-IDF vectors...\n",
      "\n",
      "TF-IDF Vectorization complete!\n",
      "TF-IDF matrix shape: (412, 1000)\n",
      "  Samples (documents): 412\n",
      "  Features (vocabulary): 1000\n",
      "  Sparsity: 98.49%\n",
      "\n",
      "Vocabulary size: 1000\n",
      "Sample features: ['abgeordneter' 'abgeordneter dr' 'abgeordneter frau' 'abs' 'abschließen'\n",
      " 'abschließend' 'absehen' 'absolut' 'abstimmung' 'aktiv' 'aktuell' 'all'\n",
      " 'allgemein' 'alt' 'alternative' 'amerikanisch' 'amnesty'\n",
      " 'amnesty international' 'anbieten' 'anderer']\n",
      "\n",
      "Top 10 TF-IDF terms for first document:\n",
      "  präsidentin: 0.4746\n",
      "  frau präsidentin: 0.4746\n",
      "  herr: 0.4165\n",
      "  frau: 0.4011\n",
      "  dame herr: 0.3279\n",
      "  dame: 0.3279\n",
      "  überzeugung: 0.0000\n",
      "  überweisungsvorschlag: 0.0000\n",
      "  überprüfung: 0.0000\n",
      "  ansatz: 0.0000\n",
      "\n",
      "TF-IDF vectorizer and matrix ready for topic modeling!\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization of lemmatized texts\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "print(\"TF-IDF Vectorization\")\n",
    "print(\"Converting lemmatized texts to TF-IDF vectors...\")\n",
    "\n",
    "# Initialize TfidfVectorizer with German-specific parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,          # Limit vocabulary to top 1000 features\n",
    "    min_df=2,                   # Minimum document frequency\n",
    "    max_df=0.8,                 # Maximum document frequency (80% of docs)\n",
    "    ngram_range=(1, 2),         # Use unigrams and bigrams\n",
    "    sublinear_tf=True,          # Apply sublinear term frequency scaling\n",
    "    norm='l2'                   # L2 normalization\n",
    ")\n",
    "\n",
    "# Convert lemmatized texts to TF-IDF vectors\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text_lemmatized'])\n",
    "\n",
    "print(f\"\\nTF-IDF Vectorization complete!\")\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  Samples (documents): {tfidf_matrix.shape[0]}\")\n",
    "print(f\"  Features (vocabulary): {tfidf_matrix.shape[1]}\")\n",
    "print(f\"  Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "print(f\"\\nVocabulary size: {len(feature_names)}\")\n",
    "print(f\"Sample features: {feature_names[:20]}\")\n",
    "\n",
    "# Convert sparse matrix to dense for inspection\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Show top TF-IDF terms for first document\n",
    "print(f\"\\nTop 10 TF-IDF terms for first document:\")\n",
    "top_indices = tfidf_dense[0].argsort()[-10:][::-1]\n",
    "for idx in top_indices:\n",
    "    print(f\"  {feature_names[idx]}: {tfidf_dense[0, idx]:.4f}\")\n",
    "\n",
    "# Store TF-IDF matrix and vectorizer for later use\n",
    "print(f\"\\nTF-IDF vectorizer and matrix ready for topic modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0388207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topic Modeling\n",
      "Training LDA model with 20 topics...\n",
      "\n",
      "Document-Term Matrix created!\n",
      "Matrix shape: (412, 147)\n",
      "  Documents: 412\n",
      "  Terms (vocabulary): 147\n",
      "  Sparsity: 95.95%\n",
      "\n",
      "Training LDA model with 30 topics...\n",
      "iteration: 1 of max_iter: 30\n",
      "iteration: 2 of max_iter: 30\n",
      "iteration: 3 of max_iter: 30\n",
      "iteration: 4 of max_iter: 30\n",
      "iteration: 5 of max_iter: 30\n",
      "iteration: 6 of max_iter: 30\n",
      "iteration: 7 of max_iter: 30\n",
      "iteration: 8 of max_iter: 30\n",
      "iteration: 9 of max_iter: 30\n",
      "iteration: 10 of max_iter: 30\n",
      "iteration: 11 of max_iter: 30\n",
      "iteration: 12 of max_iter: 30\n",
      "iteration: 13 of max_iter: 30\n",
      "iteration: 14 of max_iter: 30\n",
      "iteration: 15 of max_iter: 30\n",
      "iteration: 16 of max_iter: 30\n",
      "iteration: 17 of max_iter: 30\n",
      "iteration: 18 of max_iter: 30\n",
      "iteration: 19 of max_iter: 30\n",
      "iteration: 20 of max_iter: 30\n",
      "iteration: 21 of max_iter: 30\n",
      "iteration: 22 of max_iter: 30\n",
      "iteration: 23 of max_iter: 30\n",
      "iteration: 24 of max_iter: 30\n",
      "iteration: 25 of max_iter: 30\n",
      "iteration: 26 of max_iter: 30\n",
      "iteration: 27 of max_iter: 30\n",
      "iteration: 28 of max_iter: 30\n",
      "iteration: 29 of max_iter: 30\n",
      "iteration: 30 of max_iter: 30\n",
      "\n",
      "LDA Model Training Complete!\n",
      "Model parameters:\n",
      "  Number of topics: 30\n",
      "  Number of iterations: 30\n",
      "  Perplexity: 195.2157\n",
      "  Score: -18628.1401\n",
      "\n",
      "================================================================================\n",
      "TOP 10 TERMS FOR EACH TOPIC\n",
      "================================================================================\n",
      "\n",
      "Topic  1: unser, haus, weg, nehmen, antwort, erwarten, kollegin, beratung, rede, hoch\n",
      "\n",
      "Topic  2: thema, letzter, unterschiedlich, ergebnis, punkt, abgeordneter, halten, herr, kollege, insbesondere\n",
      "\n",
      "Topic  3: zukunft, aufgabe, eigentlich, politisch, entsprechend, kollege, herr bundeskanzler, mensch, bundeskanzler, sehen\n",
      "\n",
      "Topic  4: deutsch, deutschland, geben, dm, haus, dr, stellen, klar, herr, arbeiten\n",
      "\n",
      "Topic  5: insbesondere, gebiet, richtig, lassen, erreichen, auffassung, interesse, bitte, bereich, hoch\n",
      "\n",
      "Topic  6: stehen, zeigen, verfügung, sinn, haus, ziel, rede, bund, richtig, stark\n",
      "\n",
      "Topic  7: glauben, tun, ding, million, fallen, punkt, anderer, sache, unseren, entscheiden\n",
      "\n",
      "Topic  8: mensch, können, notwendig, sinn, land, grund, handeln, art, frage, entscheidend\n",
      "\n",
      "Topic  9: deutsch, fall, einheit, kommen, nehmen, unseren, dm, mensch, verfügung, gut\n",
      "\n",
      "Topic 10: genau, antrag, frau, kollegin, kollege, spd, schaffen, glauben, einheit, geben\n",
      "\n",
      "Topic 11: herr, notwendig, bundeskanzler, art, herr bundeskanzler, glauben, handeln, sagen, satz, falsch\n",
      "\n",
      "Topic 12: frage, herr, staatssekretär, abgeordneter, kollege, dr, bundesregierung, herr kollege, antwort, übrig\n",
      "\n",
      "Topic 13: gesellschaft, sagen, kollege, gemeinsam, zukunft, wissen, land, herr, problem, herr kollege\n",
      "\n",
      "Topic 14: bund, brauchen, antrag, fraktion, letzter, satz, bundesrepublik, dm, spd, ausschuß\n",
      "\n",
      "Topic 15: weg, bringen, punkt, entscheidend, arbeiten, hoch, problem, deutschland, zeigen, frau\n",
      "\n",
      "Topic 16: deutsche, bundestag, deutsche bundestag, sprechen, regierung, entscheidend, ding, unser, müssen, rede\n",
      "\n",
      "Topic 17: mensch, europa, darstellen, führen, politisch, antwort, bundesregierung, leben, deutsche, punkt\n",
      "\n",
      "Topic 18: frage, deutschland, antwort, sagen, abgeordneter, führen, herr, kollege, hoch, tun\n",
      "\n",
      "Topic 19: arbeit, spd, genau, präsident, frau, bitte, unterschiedlich, sehen, deutschland, gut\n",
      "\n",
      "Topic 20: deutlich, liegen, kind, stelle, ziel, sagen, bundestag, notwendig, geben, feststellen\n",
      "\n",
      "Topic 21: frau, ausschuß, fraktion, beratung, abgeordneter, dr, antrag, gesetz, bericht, bundesregierung\n",
      "\n",
      "Topic 22: herr, liegen, minister, grund, präsident, erwarten, herr präsident, ergebnis, lage, unterschiedlich\n",
      "\n",
      "Topic 23: wort, kollege, fraktion, erreichen, unser, deutsche bundestag, zeigen, ding, leben, wichtig\n",
      "\n",
      "Topic 24: land, bundesregierung, regelung, gesetz, unser, regierung, bedeuten, unser land, unseren, ziel\n",
      "\n",
      "Topic 25: frau, darstellen, dr, ausschuß, fraktion, abgeordneter, beratung, herr, mensch, arbeit\n",
      "\n",
      "Topic 26: million, kommen, brauchen, entscheiden, deutsche, dm, stellen, verfügung, deutsche bundestag, wort\n",
      "\n",
      "Topic 27: kind, brauchen, frage, antwort, partei, aufgabe, situation, unseren, gehören, stellen\n",
      "\n",
      "Topic 28: deutsche bundestag, situation, spd, verfügung, bedeuten, seite, erkennen, nehmen, übrig, unterschiedlich\n",
      "\n",
      "Topic 29: beratung, verfügung, sagen, liegen, präsident, bundesrepublik, bereich, falsch, unser, erreichen\n",
      "\n",
      "Topic 30: herr, dame herr, dame, politisch, sagen, sehen, kollege, bundesregierung, präsident, frage\n",
      "\n",
      "================================================================================\n",
      "LDA Model ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# LDA Topic Modeling with optimized parameters\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "print(\"LDA Topic Modeling\")\n",
    "print(\"Training LDA model with 20 topics...\")\n",
    "\n",
    "# LDA requires CountVectorizer, not TF-IDF\n",
    "# Create CountVectorizer with the specified parameters\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    min_df=10,               # Minimum document frequency (seltene Wörter raus)\n",
    "    max_df=0.90,            # Maximum document frequency (sehr häufige Wörter raus)\n",
    "    ngram_range=(1, 2),     # Unigrams and bigrams\n",
    "    stop_words='english'    # Basic English stopwords (additional filter)\n",
    ")\n",
    "\n",
    "# Fit and transform the texts\n",
    "doc_term_matrix = count_vectorizer.fit_transform(df['text_lemmatized'])\n",
    "\n",
    "print(f\"\\nDocument-Term Matrix created!\")\n",
    "print(f\"Matrix shape: {doc_term_matrix.shape}\")\n",
    "print(f\"  Documents: {doc_term_matrix.shape[0]}\")\n",
    "print(f\"  Terms (vocabulary): {doc_term_matrix.shape[1]}\")\n",
    "print(f\"  Sparsity: {(1 - doc_term_matrix.nnz / (doc_term_matrix.shape[0] * doc_term_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Initialize and train LDA model\n",
    "n_topics = 30\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=30,\n",
    "    learning_method='online',\n",
    "    n_jobs=-1,              # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining LDA model with {n_topics} topics...\")\n",
    "lda_model.fit(doc_term_matrix)\n",
    "\n",
    "print(f\"\\nLDA Model Training Complete!\")\n",
    "print(f\"Model parameters:\")\n",
    "print(f\"  Number of topics: {n_topics}\")\n",
    "print(f\"  Number of iterations: {lda_model.max_iter}\")\n",
    "print(f\"  Perplexity: {lda_model.perplexity(doc_term_matrix):.4f}\")\n",
    "print(f\"  Score: {lda_model.score(doc_term_matrix):.4f}\")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = np.array(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display top terms for each topic\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 TERMS FOR EACH TOPIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_top_words = 10\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    print(f\"\\nTopic {topic_idx + 1:2d}: {', '.join(top_words)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"LDA Model ready for analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9db7887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\olive\\miniconda3\\envs\\parl_speech\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967be269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score Berechnung\n",
      "Calculating coherence metrics for the LDA model...\n",
      "\n",
      "Perplexity Score: 195.2157\n",
      "  (Interpretation: niedriger ist besser)\n",
      "\n",
      "================================================================================\n",
      "COHERENCE SCORES\n",
      "================================================================================\n",
      "\n",
      "Average Topic Coherence: 0.2386\n",
      "  (Range: 0-1, höher ist besser. >0.5 ist akzeptabel)\n",
      "\n",
      "Coherence scores by topic:\n",
      "  Topic  1: 0.1908\n",
      "  Topic  2: 0.2021\n",
      "  Topic  3: 0.1798\n",
      "  Topic  4: 0.2491\n",
      "  Topic  5: 0.3895\n",
      "  Topic  6: 0.1731\n",
      "  Topic  7: 0.2179\n",
      "  Topic  8: 0.2304\n",
      "  Topic  9: 0.1315\n",
      "  Topic 10: 0.2246\n",
      "  Topic 11: 0.2804\n",
      "  Topic 12: 0.2359\n",
      "  Topic 13: 0.2697\n",
      "  Topic 14: 0.1731\n",
      "  Topic 15: 0.1509\n",
      "  Topic 16: 0.3098\n",
      "  Topic 17: 0.2410\n",
      "  Topic 18: 0.2432\n",
      "  Topic 19: 0.1295\n",
      "  Topic 20: 0.2375\n",
      "  Topic 21: 0.3918\n",
      "  Topic 22: 0.2812\n",
      "  Topic 23: 0.2027\n",
      "  Topic 24: 0.3143\n",
      "  Topic 25: 0.3473\n",
      "  Topic 26: 0.1716\n",
      "  Topic 27: 0.1568\n",
      "  Topic 28: 0.1710\n",
      "  Topic 29: 0.2150\n",
      "  Topic 30: 0.4466\n",
      "\n",
      "Log-Likelihood per document: -45.2139\n",
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION SUMMARY\n",
      "================================================================================\n",
      "Number of Topics: 20\n",
      "Number of Documents: 412\n",
      "Vocabulary Size: 147\n",
      "\n",
      "Perplexity: 195.2157\n",
      "Average Topic Coherence: 0.2386\n",
      "Log-Likelihood: -18628.1401\n",
      "\n",
      "Interpretation: ✗ Modell könnte verbessert werden\n"
     ]
    }
   ],
   "source": [
    "# Coherence Score Berechnung\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"Coherence Score Berechnung\")\n",
    "print(\"Calculating coherence metrics for the LDA model...\")\n",
    "\n",
    "# Calculate Perplexity\n",
    "perplexity = lda_model.perplexity(doc_term_matrix)\n",
    "print(f\"\\nPerplexity Score: {perplexity:.4f}\")\n",
    "print(f\"  (Interpretation: niedriger ist besser)\")\n",
    "\n",
    "# Calculate topic coherence manually\n",
    "# Method: Measure similarity between top words in each topic\n",
    "def calculate_topic_coherence(lda_model, doc_term_matrix, feature_names, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate coherence of topics based on co-occurrence of top words\n",
    "    \"\"\"\n",
    "    # Convert to dense for easier computation\n",
    "    dtm_dense = doc_term_matrix.toarray()\n",
    "    \n",
    "    coherence_scores = []\n",
    "    \n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        # Get top words for this topic\n",
    "        top_word_indices = topic.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        # Calculate pairwise similarity between top words based on document co-occurrence\n",
    "        word_vectors = dtm_dense[:, top_word_indices]\n",
    "        \n",
    "        # Calculate cosine similarity between word vectors\n",
    "        if word_vectors.shape[1] > 1:\n",
    "            similarity_matrix = cosine_similarity(word_vectors.T)\n",
    "            # Get average similarity (excluding diagonal)\n",
    "            np.fill_diagonal(similarity_matrix, 0)\n",
    "            avg_similarity = similarity_matrix.sum() / (word_vectors.shape[1] * (word_vectors.shape[1] - 1))\n",
    "            coherence_scores.append(avg_similarity)\n",
    "    \n",
    "    return np.mean(coherence_scores), coherence_scores\n",
    "\n",
    "# Get feature names from count vectorizer\n",
    "feature_names = np.array(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Calculate coherence\n",
    "avg_coherence, topic_coherences = calculate_topic_coherence(lda_model, doc_term_matrix, feature_names)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COHERENCE SCORES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAverage Topic Coherence: {avg_coherence:.4f}\")\n",
    "print(f\"  (Range: 0-1, höher ist besser. >0.5 ist akzeptabel)\")\n",
    "\n",
    "# Show individual topic coherence scores\n",
    "print(f\"\\nCoherence scores by topic:\")\n",
    "for topic_idx, coherence in enumerate(topic_coherences):\n",
    "    print(f\"  Topic {topic_idx + 1:2d}: {coherence:.4f}\")\n",
    "\n",
    "# Calculate log-likelihood per document\n",
    "log_likelihood = lda_model.score(doc_term_matrix)\n",
    "print(f\"\\nLog-Likelihood per document: {log_likelihood / doc_term_matrix.shape[0]:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of Topics: 20\")\n",
    "print(f\"Number of Documents: {doc_term_matrix.shape[0]}\")\n",
    "print(f\"Vocabulary Size: {doc_term_matrix.shape[1]}\")\n",
    "print(f\"\\nPerplexity: {perplexity:.4f}\")\n",
    "print(f\"Average Topic Coherence: {avg_coherence:.4f}\")\n",
    "print(f\"Log-Likelihood: {log_likelihood:.4f}\")\n",
    "print(f\"\\nInterpretation: {'✓ Gutes Modell' if avg_coherence > 0.5 else '✗ Modell könnte verbessert werden'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parl_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
